{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Step 0 - Preprocessing</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we first read the data including the bug reports and source code files of all 12 projects and for ease of access, we save them as two pickle files in the ./Data directory. Therefore, this set of code will populate the ./Data directory with \"allBugReports.pickle\" which is a pandas dataframe that contains all the bug reports from all projects and \"allSourceCodes.pickle\" which is a pandas dataframe that contains all source files after preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: javalang in /home/sepehr/anaconda3/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: six in /home/sepehr/anaconda3/lib/python3.8/site-packages (from javalang) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "import warnings\n",
    "import javalang\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from scipy import spatial\n",
    "import scipy.spatial.distance\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm as tq\n",
    "from time import gmtime, strftime\n",
    "from random import randint\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Splitting code and natural language</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading source codes into pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classNames_methodNames(node):\n",
    "    result=''\n",
    "    if isinstance(node,javalang.tree.MethodDeclaration) or isinstance(node,javalang.tree.ClassDeclaration):\n",
    "        return node.name.lower()+' '\n",
    "    if not (isinstance(node,javalang.tree.PackageDeclaration) or\n",
    "        isinstance(node,javalang.tree.FormalParameter) or\n",
    "       isinstance(node,javalang.tree.Import)):\n",
    "        if node:\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=classNames_methodNames(childNode)\n",
    "    return result\n",
    "    \n",
    "def traverse_node(node,i=0):\n",
    "    i+=1\n",
    "    result=''\n",
    "    if not(isinstance(node,javalang.tree.PackageDeclaration)\n",
    "            or isinstance(node,javalang.tree.FormalParameter)            \n",
    "            or isinstance(node,javalang.tree.Import)\n",
    "            or isinstance(node,javalang.tree.CompilationUnit)):\n",
    "        if node:\n",
    "            if (isinstance(node,int) or isinstance(node,str) or isinstance(node,float)) and i==2:\n",
    "                result+=node+' '\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=traverse_node(childNode,i)\n",
    "    return result\n",
    "\n",
    "def code_parser(code):\n",
    "    try:\n",
    "        tree = javalang.parse.parse(code)\n",
    "        return ''.join([traverse_node(node) for path, node in tree]) + ' ' + ''.join([classNames_methodNames(node)\n",
    "                                                                                      for path, node in tree])\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return ''\n",
    "\n",
    "\n",
    "def loadSourceFiles2df(PATH,project):\n",
    "    \"\"\"\n",
    "    Receives: group name and project name \n",
    "    Process: open the source file directory and finds all the java files,\n",
    "             and after preprocessing(using code_preprocessor) load them into a pandas dataframe \n",
    "    Returns: dataframe >> \"filename\",\"code\",\"size\"\n",
    "    \"\"\"\n",
    "    print('Loading source files of {}  ...'.format(project))\n",
    "    PATH=os.path.join(\"data\",project,\"gitrepo\")\n",
    "    all_source_files=glob.glob(PATH+'/**/*.java', recursive=True)\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    sourceCodesList=[]\n",
    "\n",
    "    for filename in tq(all_source_files):\n",
    "        code=open(filename,encoding='ISO-8859-1').read()\n",
    "        if 'src/' in filename:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split('src/')[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "        else:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split(project)[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "    source_codes_df=source_codes_df.append(pd.DataFrame(sourceCodesList))\n",
    "    return source_codes_df\n",
    "\n",
    "def load_all_SCs(dataPath):\n",
    "    print('\\tLoading all source codes ... ')\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        source_path=os.path.join(dataPath,project,\"gitrepo\")\n",
    "        source_codes_df=source_codes_df.append(loadSourceFiles2df(source_path,project))\n",
    "    return source_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading bug reports pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBugs2df(PATH,project):\n",
    "    \"\"\"\n",
    "    @Receives: the path to bug repository (the xml file)\n",
    "    @Process: Parses the xml file and reads the fix files per bug id. \n",
    "    @Returns: Returns the dataframe\n",
    "    \"\"\"\n",
    "    print(\"Loading Bug reports ... \")\n",
    "    all_bugs_df=pd.DataFrame([],columns=[\"id\",\"fix\",\"text\",\"fixdate\"])\n",
    "    bugRepo = ET.parse(PATH).getroot()\n",
    "    buglist=[]                   \n",
    "    for bug in tq(bugRepo.findall('bug')):\n",
    "        bugDict=dict({\"id\":bug.attrib['id'],\"fix\":[],\"fixdate\":bug.attrib['fixdate']\n",
    "                      ,\"summary\":None,\"description\":None,\"project\":project,\"average_precision\":0.0})\n",
    "        for bugDetail in bug.find('buginformation'):\n",
    "            if bugDetail.tag=='summary':\n",
    "                bugDict[\"summary\"]=bugDetail.text\n",
    "            elif bugDetail.tag=='description':\n",
    "                bugDict[\"description\"]=bugDetail.text\n",
    "        bugDict[\"fix\"]=np.array([fixFile.text.replace('/','.').lower() for fixFile in bug.find('fixedFiles')])\n",
    "        summary=str(bugDict['summary']) if str(bugDict['summary']) !=np.nan else \"\"\n",
    "        description=str(bugDict['description']) if str(bugDict['description']) !=np.nan else \"\"\n",
    "        buglist.append(bugDict)\n",
    "    all_bugs_df=all_bugs_df.append(pd.DataFrame(buglist))\n",
    "    return all_bugs_df.set_index('id')\n",
    "\n",
    "def load_all_BRs(dataPath):\n",
    "    print('\\tLoading all bug reports ... ')\n",
    "    all_bugs_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        data_path=os.path.join(dataPath,project,\"bugrepo\",\"repository.xml\")\n",
    "        all_bugs_df=all_bugs_df.append(loadBugs2df(data_path,project))\n",
    "        print(len(all_bugs_df))\n",
    "    return all_bugs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Main Preprocessing class</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingUnit:\n",
    "\n",
    "    all_projects_source_codes=pd.DataFrame([])\n",
    "    all_projects_bugreports=pd.DataFrame([])\n",
    "    \n",
    "    def __init__(self,dataPath):\n",
    "\n",
    "        self.dataPath=dataPath\n",
    "        self.dataFolder=os.path.join(os.getcwd(),'Output')\n",
    "        if not os.path.exists(self.dataFolder):\n",
    "            os.makedirs(self.dataFolder)\n",
    "            \n",
    "    def execute(self):\n",
    "\n",
    "        self.loadEverything()\n",
    "\n",
    "    def loadEverything(self):\n",
    "        vectorize=False\n",
    "        if PreprocessingUnit.all_projects_bugreports.empty:\n",
    "            bugReportFile=os.path.join(self.dataFolder,'allBugReports.pickle')\n",
    "            if not os.path.isfile(bugReportFile):\n",
    "                PreprocessingUnit.all_projects_bugreports=load_all_BRs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_bugreports.to_pickle(bugReportFile)\n",
    "            else: \n",
    "                PreprocessingUnit.all_projects_bugreports=pd.read_pickle(bugReportFile)\n",
    "        print(\"*** All bug reports are are preprocessed and stored as: {} ***\".format('/'.join(bugReportFile.split('/')[-2:])))\n",
    "\n",
    "        if PreprocessingUnit.all_projects_source_codes.empty:\n",
    "            sourceCodeFile=os.path.join(self.dataFolder,'allSourceCodes.pickle')\n",
    "            if not os.path.isfile(sourceCodeFile):\n",
    "                PreprocessingUnit.all_projects_source_codes=load_all_SCs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_source_codes.to_pickle(sourceCodeFile)\n",
    "            else:\n",
    "                PreprocessingUnit.all_projects_source_codes=pd.read_pickle(sourceCodeFile)\n",
    "        print(\"*** All source codes are preprocessed and stored as: {} ***\".format('/'.join(sourceCodeFile.split('/')[-2:])))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoading all bug reports ... \n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33e4deb06464a058d1934eadc02c212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2647fc2e704e5b8e533f5b819aa8fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68aa2bc8af1f48d882129d14f119479a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e1972a739548a4a44885ff3665002c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa648d730f5f48689fe1e1ffb6f2edc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e894c13a4a65491a97e6b962d4d32ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/271 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1220\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdc2ddac9c046ebb643376090d3e388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f488629b97a348a8b3af6160d1b84804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1326\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d47334836f14efab8c715380bb4f10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948b6adfcdcf4d4d857c1297171dc9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/158 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1701\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32b7338a7fb4bff9c16ee6034671b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1833\n",
      "Loading Bug reports ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0129561dd9460f87b1439c69283ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858\n",
      "*** All bug reports are are preprocessed and stored as: Output/allBugReports.pickle ***\n",
      "\tLoading all source codes ... \n",
      "Loading source files of SPR  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e211ddb7d844cda1c11c49c75e68f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of LDAP  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f580246892e1407ab4a2363f924ba579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of COLLECTIONS  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a81db552fe14715befe9b0924a8c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of CONFIGURATION  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33766353132a4d8f87caf4c8f6e52511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of SEC  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b9389092fe4166b283becd14b36e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of DATAMONGO  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4dda232ede4cb29e9d62f638a8a1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of SOCIALFB  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854dcbc83caf4ba08728b76e0edcbf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of IO  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a29f88fc5d34074a53f01d5f1ad2f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of LANG  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb64c0b47844f098ebf8e677cb59246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of DATACMNS  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db22a6563ff44643ac4d00224603ffa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of DATAREST  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a6f283e18940168ca32b8584da878e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading source files of ELY  ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37319982dc2d4977a2ada38874c8e658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All source codes are preprocessed and stored as: Output/allSourceCodes.pickle ***\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    config={'DATA_PATH':os.path.join('data')}\n",
    "    preprocessor=PreprocessingUnit(dataPath=config['DATA_PATH'])\n",
    "    preprocessor.execute()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fix                    [org.springframework.jms.support.jmsutils.java]\n",
       "text                                                               NaN\n",
       "fixdate                                            2009-05-27 21:40:44\n",
       "summary              NullPointerException in JmsUtils.buildExceptio...\n",
       "description          I triggered  this by fetching an invalid JMS m...\n",
       "project                                                            SPR\n",
       "average_precision                                                  0.0\n",
       "Name: 5785, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/*\\n * Copyright 2002-2012 the original author or authors.\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *      http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\npackage org.springframework.mock.web.portlet;\\n\\nimport javax.portlet.Event;\\nimport javax.portlet.EventRequest;\\nimport javax.portlet.PortalContext;\\nimport javax.portlet.PortletContext;\\n\\n/**\\n * Mock implementation of the {@link javax.portlet.EventRequest} interface.\\n *\\n * @author Juergen Hoeller\\n * @since 3.0\\n */\\npublic class MockEventRequest extends MockPortletRequest implements EventRequest {\\n\\n\\tprivate final Event event;\\n\\n\\tprivate String method;\\n\\n\\n\\t/**\\n\\t * Create a new MockEventRequest with a default {@link MockPortalContext}\\n\\t * and a default {@link MockPortletContext}.\\n\\t * @param event the event that this request wraps\\n\\t * @see MockEvent\\n\\t */\\n\\tpublic MockEventRequest(Event event) {\\n\\t\\tsuper();\\n\\t\\tthis.event = event;\\n\\t}\\n\\n\\t/**\\n\\t * Create a new MockEventRequest with a default {@link MockPortalContext}.\\n\\t * @param event the event that this request wraps\\n\\t * @param portletContext the PortletContext that the request runs in\\n\\t * @see MockEvent\\n\\t */\\n\\tpublic MockEventRequest(Event event, PortletContext portletContext) {\\n\\t\\tsuper(portletContext);\\n\\t\\tthis.event = event;\\n\\t}\\n\\n\\t/**\\n\\t * Create a new MockEventRequest.\\n\\t * @param event the event that this request wraps\\n\\t * @param portalContext the PortletContext that the request runs in\\n\\t * @param portletContext the PortletContext that the request runs in\\n\\t */\\n\\tpublic MockEventRequest(Event event, PortalContext portalContext, PortletContext portletContext) {\\n\\t\\tsuper(portalContext, portletContext);\\n\\t\\tthis.event = event;\\n\\t}\\n\\n\\n\\t@Override\\n\\tprotected String getLifecyclePhase() {\\n\\t\\treturn EVENT_PHASE;\\n\\t}\\n\\n\\t@Override\\n\\tpublic Event getEvent() {\\n\\t\\treturn this.event;\\n\\t}\\n\\n\\tpublic void setMethod(String method) {\\n\\t\\tthis.method = method;\\n\\t}\\n\\n\\t@Override\\n\\tpublic String getMethod() {\\n\\t\\treturn this.method;\\n\\t}\\n\\n}'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "display(all_projects_bugreports.iloc[10])\n",
    "display(all_projects_source_codes.iloc[10].unprocessed_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59492509ee09bb1e98cb3b73aca52e57ed875f73ef434eaac26b9b50866a2d0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
