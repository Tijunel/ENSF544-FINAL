{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Step 0 - Preprocessing</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we first read the data including the bug reports and source code files of all 12 projects and for ease of access, we save them as two pickle files in the ./Output directory. Therefore, this set of code will populate the ./Output directory with \"allBugReports.pickle\" which is a pandas dataframe that contains all the bug reports from all projects and \"allSourceCodes.pickle\" which is a pandas dataframe that contains all source files after preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: javalang in /Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: six in /Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages (from javalang) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "import javalang\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "import multiprocessing\n",
    "from tqdm.notebook import tqdm as tq\n",
    "from time import gmtime, strftime\n",
    "from random import randint\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Splitting code and natural language</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading source codes into pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classNames_methodNames(node):\n",
    "    result=''\n",
    "    if isinstance(node,javalang.tree.MethodDeclaration) or isinstance(node,javalang.tree.ClassDeclaration):\n",
    "        return node.name.lower()+' '\n",
    "    if not (isinstance(node,javalang.tree.PackageDeclaration) or\n",
    "        isinstance(node,javalang.tree.FormalParameter) or\n",
    "       isinstance(node,javalang.tree.Import)):\n",
    "        if node:\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=classNames_methodNames(childNode)\n",
    "    return result\n",
    "    \n",
    "def traverse_node(node,i=0):\n",
    "    i+=1\n",
    "    result=''\n",
    "    if not(isinstance(node,javalang.tree.PackageDeclaration)\n",
    "            or isinstance(node,javalang.tree.FormalParameter)            \n",
    "            or isinstance(node,javalang.tree.Import)\n",
    "            or isinstance(node,javalang.tree.CompilationUnit)):\n",
    "        if node:\n",
    "            if (isinstance(node,int) or isinstance(node,str) or isinstance(node,float)) and i==2:\n",
    "                result+=node+' '\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=traverse_node(childNode,i)\n",
    "    return result\n",
    "\n",
    "def code_parser(code):\n",
    "    try:\n",
    "        tree = javalang.parse.parse(code)\n",
    "        return ''.join([traverse_node(node) for path, node in tree]) + ' ' + ''.join([classNames_methodNames(node)\n",
    "                                                                                      for path, node in tree])\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return ''\n",
    "\n",
    "def loadSourceFiles2df(PATH,project):\n",
    "    \"\"\"\n",
    "    Receives: group name and project name \n",
    "    Process: open the source file directory and finds all the java files,\n",
    "             and after preprocessing(using code_preprocessor) load them into a pandas dataframe \n",
    "    Returns: dataframe >> \"filename\",\"code\",\"size\"\n",
    "    \"\"\"\n",
    "    print('Loading source files of {}  ...'.format(project))\n",
    "    PATH=os.path.join(\"data\",project,\"gitrepo\")\n",
    "    all_source_files=glob.glob(PATH+'/**/*.java', recursive=True)\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    sourceCodesList=[]\n",
    "\n",
    "    for filename in tq(all_source_files):\n",
    "        code=open(filename,encoding='ISO-8859-1').read()\n",
    "        if 'src/' in filename:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split('src/')[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "        else:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split(project)[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "    source_codes_df=source_codes_df.append(pd.DataFrame(sourceCodesList))\n",
    "    return source_codes_df\n",
    "\n",
    "def load_all_SCs(dataPath):\n",
    "    print('\\tLoading all source codes ... ')\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        source_path=os.path.join(dataPath,project,\"gitrepo\")\n",
    "        source_codes_df=source_codes_df.append(loadSourceFiles2df(source_path,project))\n",
    "    return source_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading bug reports pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBugs2df(PATH,project):\n",
    "    \"\"\"\n",
    "    @Receives: the path to bug repository (the xml file)\n",
    "    @Process: Parses the xml file and reads the fix files per bug id. \n",
    "    @Returns: Returns the dataframe\n",
    "    \"\"\"\n",
    "    print(\"Loading Bug reports ... \")\n",
    "    all_bugs_df=pd.DataFrame([],columns=[\"id\",\"fix\",\"text\",\"fixdate\"])\n",
    "    bugRepo = ET.parse(PATH).getroot()\n",
    "    buglist=[]                   \n",
    "    for bug in tq(bugRepo.findall('bug')):\n",
    "        bugDict=dict({\"id\":bug.attrib['id'],\"fix\":[],\"fixdate\":bug.attrib['fixdate']\n",
    "                      ,\"summary\":None,\"description\":None,\"project\":project,\"average_precision\":0.0})\n",
    "        for bugDetail in bug.find('buginformation'):\n",
    "            if bugDetail.tag=='summary':\n",
    "                bugDict[\"summary\"]=bugDetail.text\n",
    "            elif bugDetail.tag=='description':\n",
    "                bugDict[\"description\"]=bugDetail.text\n",
    "        bugDict[\"fix\"]=np.array([fixFile.text.replace('/','.').lower() for fixFile in bug.find('fixedFiles')])\n",
    "        summary=str(bugDict['summary']) if str(bugDict['summary']) !=np.nan else \"\"\n",
    "        description=str(bugDict['description']) if str(bugDict['description']) !=np.nan else \"\"\n",
    "        buglist.append(bugDict)\n",
    "    all_bugs_df=all_bugs_df.append(pd.DataFrame(buglist))\n",
    "    return all_bugs_df.set_index('id')\n",
    "\n",
    "def load_all_BRs(dataPath):\n",
    "    print('\\tLoading all bug reports ... ')\n",
    "    all_bugs_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        data_path=os.path.join(dataPath,project,\"bugrepo\",\"repository.xml\")\n",
    "        all_bugs_df=all_bugs_df.append(loadBugs2df(data_path,project))\n",
    "        print(len(all_bugs_df))\n",
    "    return all_bugs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Main Preprocessing class</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingUnit:\n",
    "    all_projects_source_codes=pd.DataFrame([])\n",
    "    all_projects_bugreports=pd.DataFrame([])\n",
    "    \n",
    "    def __init__(self,dataPath):\n",
    "        self.dataPath=dataPath\n",
    "        self.dataFolder=os.path.join(os.getcwd(),'Output')\n",
    "        if not os.path.exists(self.dataFolder):\n",
    "            os.makedirs(self.dataFolder)\n",
    "            \n",
    "    def execute(self):\n",
    "        self.loadEverything()\n",
    "\n",
    "    def loadEverything(self):\n",
    "        vectorize=False\n",
    "        if PreprocessingUnit.all_projects_bugreports.empty:\n",
    "            bugReportFile=os.path.join(self.dataFolder,'allBugReports.pickle')\n",
    "            if not os.path.isfile(bugReportFile):\n",
    "                PreprocessingUnit.all_projects_bugreports=load_all_BRs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_bugreports.to_pickle(bugReportFile)\n",
    "            else: \n",
    "                PreprocessingUnit.all_projects_bugreports=pd.read_pickle(bugReportFile)\n",
    "        print(\"*** All bug reports are are preprocessed and stored as: {} ***\".format('/'.join(bugReportFile.split('/')[-2:])))\n",
    "\n",
    "        if PreprocessingUnit.all_projects_source_codes.empty:\n",
    "            sourceCodeFile=os.path.join(self.dataFolder,'allSourceCodes.pickle')\n",
    "            if not os.path.isfile(sourceCodeFile):\n",
    "                PreprocessingUnit.all_projects_source_codes=load_all_SCs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_source_codes.to_pickle(sourceCodeFile)\n",
    "            else:\n",
    "                PreprocessingUnit.all_projects_source_codes=pd.read_pickle(sourceCodeFile)\n",
    "        print(\"*** All source codes are preprocessed and stored as: {} ***\".format('/'.join(sourceCodeFile.split('/')[-2:])))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All bug reports are are preprocessed and stored as: Output/allBugReports.pickle ***\n",
      "*** All source codes are preprocessed and stored as: Output/allSourceCodes.pickle ***\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    config={'DATA_PATH':os.path.join('data')}\n",
    "    preprocessor=PreprocessingUnit(dataPath=config['DATA_PATH'])\n",
    "    preprocessor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fix                  [org.apache.commons.lang.builder.equalsbuilder...\n",
       "text                                                               NaN\n",
       "fixdate                                            2008-01-13 07:00:40\n",
       "summary              EqualsBuilder don&apos;t compare BigDecimals c...\n",
       "description          When comparing a BigDecimal, the comparing is ...\n",
       "project                                                           LANG\n",
       "average_precision                                                  0.0\n",
       "Name: 393, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "filename            main.java.org.springframework.security.authent...\n",
       "unprocessed_code    /* Copyright 2004, 2005, 2006 Acegi Technology...\n",
       "project                                                           SEC\n",
       "Name: 428, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "display(all_projects_bugreports.iloc[1000])\n",
    "display(all_projects_source_codes.iloc[1000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "There are several software engineering (SE) problems that can be investigated using machine learning. Among them, we will be working on a problem called \"Fault Localization\" (FL). The goal of FL is to automatically locate a fault entity (e.g. a source file, a class, a method, etc) in source code. There are different variations of FL and we will focus on Information Retrieval based FL (IRFL). This article explains FL: https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=2530&context=sis_research. \n",
    "\n",
    "In short, the idea is, given a new bug report document, we want to automatically identify the source code file that most likely needs a fix, so we can save time for debugging. \n",
    "\n",
    "To do this, we may use the previous bug resports and identify the locations (files) that have been patched as our training set. So, we build an IRFL model that:\n",
    "\n",
    "- Finds the textual similarity between the new bug report and the historical ones. \n",
    "- Then rank historically patched source files based on how similar their bug reports are to the new bug report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key Imports\n",
    "import re, string\n",
    "import pytest\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "First, we need to create our training set. Using `all_projects_bug_reports` and `all_projects_source_codes`.\n",
    "\n",
    "We will clean the bug report and source code text by creating a function that:\n",
    "\n",
    "1. Makes all text lowercase\n",
    "2. Removes all punctuation from the text\n",
    "3. Removes all repetitive white space from the text\n",
    "4. Tokenizes the filtered string and removes stem words\n",
    "\n",
    "Then, we will extract the features and labels of the bug report by:\n",
    "\n",
    "1. Concatenating the bug summary and description, then using the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Processes the given text by changing all text to lowercase, removing punctuation, removing repetitive \n",
    "  whitespace, tokenizing words, and finally stemming all words.\n",
    "  Return a string containing tokenized stem words separated by a single space.\n",
    "  \"\"\"\n",
    "  # Change text to lower case\n",
    "  text = text.lower()\n",
    "\n",
    "  # Remove any and all punctuation\n",
    "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "  # Remove any repetitive whitespace\n",
    "  text = re.sub(\"\\s\\s+\", \" \", text)\n",
    "\n",
    "  # Tokenize the words and remove all stop words\n",
    "  tokenized = word_tokenize(text)\n",
    "  tokens = []\n",
    "  for token in tokenized:\n",
    "    if token not in stopwords:\n",
    "      tokens.append(token)\n",
    "\n",
    "  # Stem all words using Porter Stemming\n",
    "  stemmer = PorterStemmer()\n",
    "  tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "  # Recreate the text\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "def process_bug_reports(bug_reports):\n",
    "  clean_bug_reports = {\n",
    "    \"fix\": [],\n",
    "    \"project\": [],\n",
    "    \"text\": [],\n",
    "    \"fixdate\": []\n",
    "  }\n",
    "  for bug_report in bug_reports:\n",
    "    # Concatenate the report's description and summary\n",
    "    description = bug_report['description']\n",
    "    summary = bug_report['summary']\n",
    "    bug_text = \"\"\n",
    "    if isinstance(description, str):\n",
    "      bug_text += description\n",
    "    if isinstance(summary, str):\n",
    "      bug_text += summary\n",
    "\n",
    "    # If the bug report is empty, we should not consider it.\n",
    "    if bug_text == \"\":\n",
    "      continue\n",
    "    \n",
    "    bug_text = clean_text(bug_text)\n",
    "\n",
    "    # Append to the clean_bug_report dictionary\n",
    "    clean_bug_reports['fix'].append(bug_report['fix'])\n",
    "    clean_bug_reports['project'].append(bug_report['project'])\n",
    "    clean_bug_reports['text'].append(bug_text)\n",
    "    clean_bug_reports['fixdate'].append(bug_report['fixdate'])\n",
    "\n",
    "  # Put the dict into a dataframe and return\n",
    "  clean_bug_reports = pd.DataFrame.from_dict(clean_bug_reports)\n",
    "  return clean_bug_reports\n",
    "\n",
    "def process_source_files(source_files):\n",
    "  clean_source_files = {\n",
    "    \"filename\": [],\n",
    "    \"code\": [],\n",
    "    \"project\": []\n",
    "  }\n",
    "  for source_file in source_files:\n",
    "    # Clean the source file's code\n",
    "    clean_code = clean_text(source_file['unprocessed_code'])\n",
    "\n",
    "    # Append to the clean_source_files dictionary\n",
    "    clean_source_files['filename'] = source_file['filename']\n",
    "    clean_source_files['code'] = clean_code\n",
    "    clean_source_files['project'] = source_file['project']\n",
    "\n",
    "  # Put the dict into a dataframe and return\n",
    "  clean_source_files = pd.DataFrame.from_dict(clean_source_files)\n",
    "  return clean_source_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's process the bug reports and source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs = process_bug_reports(all_projects_bugreports)\n",
    "source_files = process_source_files(all_projects_source_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1\n",
    "- You preprocess the data to have a clean dataset representing source files (including the buggy ones) and the bug reports. The exact preprocessing choices are ours to make.\n",
    "- Next, apply the TF-IDF method to calculate the similarity between the new bug report (to locate) and the source code files directly. Unlike BugLocator, we ignore the historical bug reports in this step. The similarity function of Method 1 is called the direct relevancy function.\n",
    "- Finally, we rank the source files based on their textual similarity to the new bug report and present the results using proper evaluation metrics (such as MAP and MRR).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Similarities\n",
    "\n",
    "Since our dataset has multiple projects, and each project has multiple bug reports, we don't want to compare bug reports with files of a project they don't belong to. So, we will compare a bug report to all the files in its respective project. \n",
    "\n",
    "To compute similarity between a bug report and it's project file:\n",
    "\n",
    "1. Iterate through each file of the bug report's project.\n",
    "2. Create a TF-IDF vectorizer and fit and transform the file's source code since we want to compare against the source code.\n",
    "3. Transform the bug report's text with the vectorizer.\n",
    "4. Compare the similarity of the two resulting vectors using cosine distance.\n",
    "\n",
    "We will iterate through each bug report and generate its similarity, then return a list of similarities that will implicitely map to each bug report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[   scores files\n",
      "0     1.0     x\n",
      "1     0.0     y]\n"
     ]
    }
   ],
   "source": [
    "def calculate_similarity(bug_report, source_files):\n",
    "  \"\"\"\n",
    "  Calculates the text of a bug report to the set of source files \n",
    "  WITHIN THE SAME PROJECT AS THE bug_report.\n",
    "  \"\"\"\n",
    "  similarity = {\n",
    "    \"scores\": [],\n",
    "    \"files\": []\n",
    "  }\n",
    "  # For each file, we will calculate the similarity of it's source code to the bug report\n",
    "  for file in source_files:\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    source_vector = vectorizer.fit_transform([file['code']])\n",
    "    bug_vector = vectorizer.transform([bug_report['text']])\n",
    "    similarity_score = cosine_similarity(source_vector, bug_vector)[0][0]\n",
    "    similarity['scores'].append(similarity_score)\n",
    "    similarity['files'].append(file['filename'])\n",
    "\n",
    "  return pd.DataFrame.from_dict(similarity)\n",
    "\n",
    "def compute_similarities(bug_reports, source_files):\n",
    "  # First, let's find the source files for each project\n",
    "  project_files = defaultdict(list)\n",
    "  for _, source_file in source_files.iterrows():\n",
    "    project_files[source_file['project']].append(source_file)\n",
    "\n",
    "  # Then, let's compute the similarities for each bug with its projects source files\n",
    "  similarities = []\n",
    "  for _, bug_report in bug_reports.iterrows():\n",
    "    print(bug_report['project'])\n",
    "    similarity = calculate_similarity(bug_report, project_files[bug_report['project']])\n",
    "    similarities.append(similarity)\n",
    "\n",
    "  return similarities\n",
    "\n",
    "# Let's do a test\n",
    "test_bugs = pd.DataFrame.from_dict({\n",
    "  \"fix\": [\"x\"],\n",
    "  \"project\": [\"A\"],\n",
    "  \"text\": [\"delta test coordinate\"],\n",
    "  \"fixdate\": [\"a\"],\n",
    "})\n",
    "test_files = pd.DataFrame.from_dict({\n",
    "  \"filename\": [\"x\", \"y\"],\n",
    "  \"project\": [\"A\", \"A\"],\n",
    "  \"code\": [\"delta test art\", \"move time coordinate\"]\n",
    "})\n",
    "sims = compute_similarities(test_bugs, test_files)\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "\n",
    "In this step, we will develop a new IRFL method and comparing to Method 1.\n",
    "\n",
    "We will roughly implement the BugLocator tool. We will use the same preprocessing as TF-IDF code we developed for method 1 to calculate an indirect relevancy function. Then, we will use a weighted average of the direct relevancy function and indirect relevancy function to do the ranking for this method. The indirect function calculates the similarity between the new bug report and the historical ones. Then, given that we already know which exact files have been fixed for each historical bug report. So, we can map files to historical bug reports. Then, the algorithm ranks source files according to their indirect similarity (the similarity of a source file's corresponding historical report(s) to the new bug report) to the new bug report.\n",
    "\n",
    "- Method 2 MUST improve method 1 results.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3\n",
    "\n",
    "This is our brand new FL technique applicable on this dataset. The novel approach should use a machine learning/information retrieval method that is not taught in class. It is okay if the method is already proposed in the FL literature and is published, however, your code cannot be copy-pasted. This method does not need to outperform the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59492509ee09bb1e98cb3b73aca52e57ed875f73ef434eaac26b9b50866a2d0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
