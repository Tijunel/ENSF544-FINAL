{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Step 0 - Preprocessing</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we first read the data including the bug reports and source code files of all 12 projects and for ease of access, we save them as two pickle files in the ./Output directory. Therefore, this set of code will populate the ./Output directory with \"allBugReports.pickle\" which is a pandas dataframe that contains all the bug reports from all projects and \"allSourceCodes.pickle\" which is a pandas dataframe that contains all source files after preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: javalang in /Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages (0.13.0)\n",
      "Requirement already satisfied: six in /Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages (from javalang) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings\n",
    "import javalang\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import requests\n",
    "from tqdm.notebook import tqdm as tq\n",
    "from time import gmtime, strftime\n",
    "from random import randint\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Splitting code and natural language</h1></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading source codes into pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classNames_methodNames(node):\n",
    "    result=''\n",
    "    if isinstance(node,javalang.tree.MethodDeclaration) or isinstance(node,javalang.tree.ClassDeclaration):\n",
    "        return node.name.lower()+' '\n",
    "    if not (isinstance(node,javalang.tree.PackageDeclaration) or\n",
    "        isinstance(node,javalang.tree.FormalParameter) or\n",
    "       isinstance(node,javalang.tree.Import)):\n",
    "        if node:\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=classNames_methodNames(childNode)\n",
    "    return result\n",
    "    \n",
    "def traverse_node(node,i=0):\n",
    "    i+=1\n",
    "    result=''\n",
    "    if not(isinstance(node,javalang.tree.PackageDeclaration)\n",
    "            or isinstance(node,javalang.tree.FormalParameter)            \n",
    "            or isinstance(node,javalang.tree.Import)\n",
    "            or isinstance(node,javalang.tree.CompilationUnit)):\n",
    "        if node:\n",
    "            if (isinstance(node,int) or isinstance(node,str) or isinstance(node,float)) and i==2:\n",
    "                result+=node+' '\n",
    "            if isinstance(node, javalang.ast.Node):\n",
    "                for childNode in node.children:\n",
    "                    result+=traverse_node(childNode,i)\n",
    "    return result\n",
    "\n",
    "def code_parser(code):\n",
    "    try:\n",
    "        tree = javalang.parse.parse(code)\n",
    "        return ''.join([traverse_node(node) for path, node in tree]) + ' ' + ''.join([classNames_methodNames(node)\n",
    "                                                                                      for path, node in tree])\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        return ''\n",
    "\n",
    "def loadSourceFiles2df(PATH,project):\n",
    "    \"\"\"\n",
    "    Receives: group name and project name \n",
    "    Process: open the source file directory and finds all the java files,\n",
    "             and after preprocessing(using code_preprocessor) load them into a pandas dataframe \n",
    "    Returns: dataframe >> \"filename\",\"code\",\"size\"\n",
    "    \"\"\"\n",
    "    print('Loading source files of {}  ...'.format(project))\n",
    "    PATH=os.path.join(\"data\",project,\"gitrepo\")\n",
    "    all_source_files=glob.glob(PATH+'/**/*.java', recursive=True)\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    sourceCodesList=[]\n",
    "\n",
    "    for filename in tq(all_source_files):\n",
    "        code=open(filename,encoding='ISO-8859-1').read()\n",
    "        if 'src/' in filename:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split('src/')[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "        else:\n",
    "            sourceCodesList.append(dict({\"filename\":filename.split(project)[1].replace('/','.').lower(),\n",
    "                                         \"unprocessed_code\":code,\n",
    "                                         'project':project}))\n",
    "    source_codes_df=source_codes_df.append(pd.DataFrame(sourceCodesList))\n",
    "    return source_codes_df\n",
    "\n",
    "def load_all_SCs(dataPath):\n",
    "    print('\\tLoading all source codes ... ')\n",
    "    source_codes_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        source_path=os.path.join(dataPath,project,\"gitrepo\")\n",
    "        source_codes_df=source_codes_df.append(loadSourceFiles2df(source_path,project))\n",
    "    return source_codes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Loading bug reports pandas Dataframe</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBugs2df(PATH,project):\n",
    "    \"\"\"\n",
    "    @Receives: the path to bug repository (the xml file)\n",
    "    @Process: Parses the xml file and reads the fix files per bug id. \n",
    "    @Returns: Returns the dataframe\n",
    "    \"\"\"\n",
    "    print(\"Loading Bug reports ... \")\n",
    "    all_bugs_df=pd.DataFrame([],columns=[\"id\",\"fix\",\"text\",\"fixdate\"])\n",
    "    bugRepo = ET.parse(PATH).getroot()\n",
    "    buglist=[]                   \n",
    "    for bug in tq(bugRepo.findall('bug')):\n",
    "        bugDict=dict({\"id\":bug.attrib['id'],\"fix\":[],\"fixdate\":bug.attrib['fixdate']\n",
    "                      ,\"summary\":None,\"description\":None,\"project\":project,\"average_precision\":0.0})\n",
    "        for bugDetail in bug.find('buginformation'):\n",
    "            if bugDetail.tag=='summary':\n",
    "                bugDict[\"summary\"]=bugDetail.text\n",
    "            elif bugDetail.tag=='description':\n",
    "                bugDict[\"description\"]=bugDetail.text\n",
    "        bugDict[\"fix\"]=np.array([fixFile.text.replace('/','.').lower() for fixFile in bug.find('fixedFiles')])\n",
    "        summary=str(bugDict['summary']) if str(bugDict['summary']) !=np.nan else \"\"\n",
    "        description=str(bugDict['description']) if str(bugDict['description']) !=np.nan else \"\"\n",
    "        buglist.append(bugDict)\n",
    "    all_bugs_df=all_bugs_df.append(pd.DataFrame(buglist))\n",
    "    return all_bugs_df.set_index('id')\n",
    "\n",
    "def load_all_BRs(dataPath):\n",
    "    print('\\tLoading all bug reports ... ')\n",
    "    all_bugs_df=pd.DataFrame([])\n",
    "    all_projects= [folder for folder in listdir(dataPath)]\n",
    "    for project in all_projects:\n",
    "        data_path=os.path.join(dataPath,project,\"bugrepo\",\"repository.xml\")\n",
    "        all_bugs_df=all_bugs_df.append(loadBugs2df(data_path,project))\n",
    "        print(len(all_bugs_df))\n",
    "    return all_bugs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><h1>Main Preprocessing class</h1></center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingUnit:\n",
    "    all_projects_source_codes=pd.DataFrame([])\n",
    "    all_projects_bugreports=pd.DataFrame([])\n",
    "    \n",
    "    def __init__(self,dataPath):\n",
    "        self.dataPath=dataPath\n",
    "        self.dataFolder=os.path.join(os.getcwd(),'Output')\n",
    "        if not os.path.exists(self.dataFolder):\n",
    "            os.makedirs(self.dataFolder)\n",
    "            \n",
    "    def execute(self):\n",
    "        self.loadEverything()\n",
    "\n",
    "    def loadEverything(self):\n",
    "        vectorize=False\n",
    "        if PreprocessingUnit.all_projects_bugreports.empty:\n",
    "            bugReportFile=os.path.join(self.dataFolder,'allBugReports.pickle')\n",
    "            if not os.path.isfile(bugReportFile):\n",
    "                PreprocessingUnit.all_projects_bugreports=load_all_BRs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_bugreports.to_pickle(bugReportFile)\n",
    "            else: \n",
    "                PreprocessingUnit.all_projects_bugreports=pd.read_pickle(bugReportFile)\n",
    "        print(\"*** All bug reports are are preprocessed and stored as: {} ***\".format('/'.join(bugReportFile.split('/')[-2:])))\n",
    "\n",
    "        if PreprocessingUnit.all_projects_source_codes.empty:\n",
    "            sourceCodeFile=os.path.join(self.dataFolder,'allSourceCodes.pickle')\n",
    "            if not os.path.isfile(sourceCodeFile):\n",
    "                PreprocessingUnit.all_projects_source_codes=load_all_SCs(dataPath=self.dataPath)\n",
    "                vectorize=True\n",
    "                PreprocessingUnit.all_projects_source_codes.to_pickle(sourceCodeFile)\n",
    "            else:\n",
    "                PreprocessingUnit.all_projects_source_codes=pd.read_pickle(sourceCodeFile)\n",
    "        print(\"*** All source codes are preprocessed and stored as: {} ***\".format('/'.join(sourceCodeFile.split('/')[-2:])))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All bug reports are are preprocessed and stored as: Output/allBugReports.pickle ***\n",
      "*** All source codes are preprocessed and stored as: Output/allSourceCodes.pickle ***\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    config={'DATA_PATH':os.path.join('data')}\n",
    "    preprocessor=PreprocessingUnit(dataPath=config['DATA_PATH'])\n",
    "    preprocessor.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** All Bug Reports are Loaded. ***\n",
      "*** All Source Codes are Loaded. ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1858"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def loadEverything():\n",
    "    all_projects_bugreports = pd.read_pickle('Output/allBugReports.pickle')\n",
    "    print(\"*** All Bug Reports are Loaded. ***\")\n",
    "    all_projects_source_codes = pd.read_pickle('Output/allSourceCodes.pickle')\n",
    "    print(\"*** All Source Codes are Loaded. ***\")\n",
    "    return all_projects_bugreports, all_projects_source_codes\n",
    "\n",
    "all_projects_bugreports, all_projects_source_codes = loadEverything()\n",
    "display(len(all_projects_bugreports))\n",
    "display(len(all_projects_source_codes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT START\n",
    "\n",
    "There are several software engineering (SE) problems that can be investigated using machine learning. Among them, we will be working on a problem called \"Fault Localization\" (FL). The goal of FL is to automatically locate a fault entity (e.g. a source file, a class, a method, etc) in source code. There are different variations of FL and we will focus on Information Retrieval based FL (IRFL). This article explains FL: https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=2530&context=sis_research\n",
    "\n",
    "In short, the idea is, given a new bug report document, we want to automatically identify the source code file that most likely needs a fix, so we can save time for debugging. \n",
    "\n",
    "To do this, we may use the previous bug resports and identify the locations (files) that have been patched as our training set. So, we build an IRFL model that:\n",
    "\n",
    "- Finds the textual similarity between the new bug report and the historical ones. \n",
    "- Then rank historically patched source files based on how similar their bug reports are to the new bug report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's import some things that will help us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/justintijunelis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/justintijunelis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Key Imports\n",
    "import re\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import multiprocessing as mp\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cores = mp.cpu_count()\n",
    "\n",
    "# Download some stuff to run the code\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "First, we need to create our training set. Using `all_projects_bug_reports` and `all_projects_source_codes`.\n",
    "\n",
    "We will clean the bug report and source code text by creating a function that will:\n",
    "\n",
    "1. Make all text lowercase.\n",
    "2. Remove all punctuation from the text and replace it with white space.\n",
    "3. Remove all repetitive white space from the text.\n",
    "4. Remove imports and packages from source code as they are not that likely to impact our bug finding ability.\n",
    "5. Space out words in camel case variables as these may provide some depth.\n",
    "6. Remove all numbers as these are unlikely to be relevant, especially with noise in comments like copyright years.\n",
    "7. Replace all duplicate white space with singular white space.\n",
    "8. Tokenize the filtered string and removes stem words\n",
    "\n",
    "Then, we will clean the bug reports by:\n",
    "\n",
    "1. Concatenating the bug summary and description, then using the our cleaner we developed earlier.\n",
    "2. Dropping any reports that are composed of entirely stopped and/or banned words.\n",
    "3. We can drop the summary and description since we will only process once.\n",
    "\n",
    "Then, we will clean the source code files by:\n",
    "\n",
    "1. Apply the clean text function to the source code.\n",
    "2. Renaming `unprocessed_code` to `code`.\n",
    "3. Dropping any source code that does not contain any filtered text.\n",
    "\n",
    "Finally, the author noticed that some of the bug reports fixed files no longer exist! These bug reports should be dropped entirely.\n",
    "\n",
    "# Potential Improvements\n",
    "\n",
    "There may be some commonalities that we could remove that are language specific. For example, words like class, void, public, private, and other common syntax in Java could help us identify the more unique parts of the source code. Additionally, we could remove copyright notices that are shared between all files. Finally, we could try to do an analysis of results with different filtering methods and see which methods create the greatest statistical difference. We could use a two-sample proportions test or a variety of other tests that could tell us if making changes makes a statistical difference. Unfortunately, the author of this report has other homework and is pretty burnt out.\n",
    "\n",
    "One further improvement to cleaning out irrelevant data is finding bug reports where some fixed files still exist, but others do not, and thus removing the files from the fixed list if they do not exist, and keeping the ones that do still exist. Although, one could argue that if any of the fixed files are missing, they should be removed entirely.\n",
    "\n",
    "We could also argue that files that have tests for them are less likely to have bugs, so we could apply some sort of weighting for files that do/don't have tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  # Remove imports\n",
    "  text = re.sub(r\"import\\s.*;\", \"\", text)\n",
    "  # Remove packages\n",
    "  text = re.sub(r\"package\\s.*;\", \"\", text)\n",
    "  # Space out camel case (https://stackoverflow.com/questions/5020906/python-convert-camel-case-to-space-delimited-using-regex-and-taking-acronyms-in)\n",
    "  text = re.sub(r\"((?<=[a-z])[A-Z]|(?<!\\A)[A-Z](?=[a-z]))\", r\" \\1\", text)\n",
    "  # Replace punctuation with spaces (https://stackoverflow.com/questions/68590438/replace-punctuation-with-space-in-text)\n",
    "  text = re.sub(r\"(?:[^\\w\\s]|_)+\", \" \", text)\n",
    "  # Replace white space or repeating whitespace with single space\n",
    "  text = re.sub(\"\\s+\", \" \", text) \n",
    "  # Remove all numbers\n",
    "  text = re.sub(r\"[0-9]+\", \"\", text)\n",
    "  # Remove HTML tags? # Remove static, int, char, etc\n",
    "  \n",
    "  # Make everything lowercase\n",
    "  text = text.lower()\n",
    "\n",
    "  # Tokenize the words, remove all stop words, and a list of common words we don't want to include\n",
    "  banned_tokens = [\"copyright\", \"void\"]\n",
    "  tokenized = word_tokenize(text) \n",
    "  tokens = []\n",
    "  for token in tokenized:\n",
    "    if token not in stopwords.words('english') and token not in banned_tokens:\n",
    "      tokens.append(token)\n",
    "\n",
    "  # Stem all words using Porter Stemming\n",
    "  stemmer = PorterStemmer()\n",
    "  tokens = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "  # Recreate the text\n",
    "  return \" \".join(tokens)\n",
    "\n",
    "def process_bug_reports(bug_reports):\n",
    "  reports_to_drop = []\n",
    "  for row, bug_report in bug_reports.iterrows():\n",
    "    description = bug_report['description']\n",
    "    summary = bug_report['summary']\n",
    "    bug_text = \"\"\n",
    "    if isinstance(description, str):\n",
    "      bug_text += description\n",
    "    if isinstance(summary, str):\n",
    "      bug_text += summary\n",
    "    bug_text = clean_text(bug_text)\n",
    "\n",
    "    # Skip and delete the row if the bug text is empty\n",
    "    if bug_text == \"\":\n",
    "      reports_to_drop.append(row)\n",
    "    else:\n",
    "      bug_reports.at[row, 'text'] = bug_text\n",
    "\n",
    "  # Drop bad reports and unnecessary columns\n",
    "  bug_reports.drop(reports_to_drop, axis = 0, inplace = True)\n",
    "  bug_reports.drop('summary', axis = 1, inplace = True)\n",
    "  bug_reports.drop('description', axis = 1, inplace = True)\n",
    "  return bug_reports\n",
    "\n",
    "def process_source_files(source_files):\n",
    "  source_files['unprocessed_code'] = source_files['unprocessed_code'].apply(lambda t: clean_text(t))\n",
    "  source_files.rename(columns={\"unprocessed_code\": \"code\"}, inplace = True)\n",
    "  source_files = source_files[source_files['code'] != \"\"]\n",
    "  return source_files\n",
    "\n",
    "def remove_irrelevant_bug_reports(bug_reports, source_files):\n",
    "  \"\"\"\n",
    "  This function removes bug reports in place where its fixed source files could not be found in the existing dataset.\n",
    "  \"\"\"\n",
    "  # Split the source files into project to improve loop efficiency (only search relevant source files for bugs)\n",
    "  projects = bug_reports['project'].unique()\n",
    "  project_source_files = defaultdict(str)\n",
    "  for project in projects:\n",
    "    project_source_files[project] = source_files[source_files['project'] == project]['filename']\n",
    "  \n",
    "  # Remove the bug reports for which no fixed source files could be found\n",
    "  reports_to_drop = []\n",
    "  for row, bug_report in bug_reports.iterrows():\n",
    "    fixed_files = bug_report['fix']\n",
    "    fixed_files_found = 0\n",
    "    for fixed_file in fixed_files:\n",
    "      for existing_file in project_source_files[bug_report['project']]:\n",
    "        if fixed_file in existing_file or fixed_file == existing_file:\n",
    "          fixed_files_found += 1\n",
    "    if fixed_files_found == 0:\n",
    "      reports_to_drop.append(row)\n",
    "\n",
    "  # Remove the irrelevant bug reports\n",
    "  bug_reports.drop(reports_to_drop, axis = 0, inplace = True)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the bug reports and source files using multiprocessing. This will take quite a while on anyone's computer. Time on an M1 Apple laptop took about 2 minutes.\n",
    "\n",
    "If you are on a PC, a windows version of the code will be executed below. However, the author of the code does not have a windows machine to test on right now so it is likely to fail. Worst case, call the functions directly without any multiprocessing, but make sure to pass copies of the dataframes, not references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  if os.name == 'posix':\n",
    "    with mp.get_context('fork').Pool(processes = cores) as p:\n",
    "      bug_reports = pd.concat(\n",
    "        p.map(\n",
    "          process_bug_reports, \n",
    "          np.array_split(all_projects_bugreports.copy(), cores)\n",
    "        )\n",
    "      )\n",
    "    with mp.get_context('fork').Pool(processes = cores) as p:\n",
    "      source_files = pd.concat(\n",
    "        p.map(\n",
    "          process_source_files, \n",
    "          np.array_split(all_projects_source_codes.copy(), cores)\n",
    "        )\n",
    "      )\n",
    "  elif os.name == 'nt': # This MIGHT work\n",
    "    with mp.Pool(processes = cores) as p:\n",
    "      bug_reports = pd.concat(\n",
    "        p.map(\n",
    "          process_bug_reports, \n",
    "          np.array_split(all_projects_bugreports.copy(), cores)\n",
    "        )\n",
    "      )\n",
    "    with mp.Pool(processes = cores) as p:\n",
    "      source_files = pd.concat(\n",
    "        p.map(\n",
    "          process_source_files, \n",
    "          np.array_split(all_projects_source_codes.copy(), cores)\n",
    "        )\n",
    "      )\n",
    "  elif os.name == 'java':\n",
    "    # Sorry\n",
    "    pass\n",
    "  remove_irrelevant_bug_reports(bug_reports, source_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Similarities\n",
    "\n",
    "Since our dataset has multiple projects, and each project has multiple bug reports, we don't want to compare bug reports with files of a project they don't belong to. So, we will compare a bug report to all the files in its respective project. \n",
    "\n",
    "To compute similarity between a bug report and it's project file:\n",
    "\n",
    "1. Iterate through each file of the bug report's project.\n",
    "2. Create a TF-IDF vectorizer and fit and transform the file's source code since we want to compare against the source code.\n",
    "3. Transform the bug report's text with the vectorizer.\n",
    "4. Compare the similarity of the two resulting vectors using cosine distance.\n",
    "\n",
    "We will iterate through each bug report and generate its similarity, then return a list of similarities that will implicitely map to each bug report.\n",
    "\n",
    "Note that inverting the vectorizer transform order was attempted but yielded worse results. This is likely because we want to fit on a larger dataset and compare bug descriptions against source code, rather than comparing source code against a bug description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(bug_report, source_files):\n",
    "  # Find the similarity score\n",
    "  vectorizer = TfidfVectorizer()\n",
    "  source_vector = vectorizer.fit_transform(source_files['code'])\n",
    "  bug_vector = vectorizer.transform([bug_report['text']])\n",
    "  similarity_score = cosine_similarity(source_vector, bug_vector)\n",
    "\n",
    "  # Extract the score\n",
    "  scores = []\n",
    "  for score in similarity_score:\n",
    "    scores.append(score[0])\n",
    "\n",
    "  # Sort the values\n",
    "  df = pd.DataFrame()\n",
    "  df['scores'] = np.array(scores)\n",
    "  df['files'] = source_files['filename'].values\n",
    "  df = df.sort_values('scores', ascending = False)\n",
    "\n",
    "  # Create a tuple array\n",
    "  tuples = []\n",
    "  for file, score in zip(df['files'].values, df['scores'].values):\n",
    "    tuples.append((file, score))\n",
    "  return tuples\n",
    "\n",
    "def compute_similarities(bug_reports, source_files):\n",
    "  for row, bug_report in bug_reports.iterrows():\n",
    "    similarity = calculate_similarity(bug_report, source_files)\n",
    "    bug_reports.at[row, 'similarities'] = similarity\n",
    "  return bug_reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarities. Again, this was built to run on POSIX machines, but there is code to run on Windows. However, it may not work as the author has not tested on a windows machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3080, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4554, in pandas._libs.hashtable.PyObjectHashTable.get_item\n  File \"pandas/_libs/hashtable_class_helper.pxi\", line 4562, in pandas._libs.hashtable.PyObjectHashTable.get_item\nKeyError: 'similarities'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3268, in _set_value\n    series = self._get_item_cache(col)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3792, in _get_item_cache\n    loc = self.columns.get_loc(item)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 3082, in get_loc\n    raise KeyError(key) from err\nKeyError: 'similarities'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-106-ea3cd35a6fd5>\", line 28, in compute_similarities\n    bug_reports.at[row, 'similarities'] = similarity\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 2167, in __setitem__\n    return super().__setitem__(key, value)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 2118, in __setitem__\n    self.obj._set_value(*key, value=value, takeable=self._takeable)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 3281, in _set_value\n    self.loc[index, col] = value\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 692, in __setitem__\n    iloc._setitem_with_indexer(indexer, value, self.name)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1604, in _setitem_with_indexer\n    self._setitem_with_indexer(new_indexer, value, name)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1635, in _setitem_with_indexer\n    self._setitem_with_indexer_split_path(indexer, value, name)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1672, in _setitem_with_indexer_split_path\n    self._setitem_with_indexer_2d_value(indexer, value)\n  File \"/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\", line 1732, in _setitem_with_indexer_2d_value\n    raise ValueError(\nValueError: Must have equal len keys and value when setting with an ndarray\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-741864d8fd72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_bug_reports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       bug_reports = pd.concat(\n\u001b[0;32m----> 9\u001b[0;31m         p.starmap(\n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mcompute_similarities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_bug_reports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject_source_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         '''\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  project_bug_reports = [group for _, group in bug_reports.groupby('project')]\n",
    "  project_source_files = [group for _, group in source_files.groupby('project')]\n",
    "  # Need to drop similarities if they exist\n",
    "  bug_reports['similarities'] = np.nan\n",
    "  if os.name == 'posix':\n",
    "    with mp.get_context('fork').Pool(processes = len(project_bug_reports)) as p:\n",
    "      bug_reports = pd.concat(\n",
    "        p.starmap(\n",
    "          compute_similarities,\n",
    "          zip(project_bug_reports, project_source_files)\n",
    "        )\n",
    "      )\n",
    "  elif os.name == 'nt':\n",
    "    with mp.Pool(processes = len(project_bug_reports)) as p:\n",
    "      bug_reports = pd.concat(\n",
    "        p.starmap(\n",
    "          compute_similarities,\n",
    "          zip(project_bug_reports, project_source_files)\n",
    "        )\n",
    "      )\n",
    "  elif os.name == 'java':\n",
    "    # Sorry\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRR (Mean Reciprocal Rank) scores\n",
    "\n",
    "Our dataset doesn't quite fit with the MRR formula, so we have to improvise. The MRR formula assumes that there is only one query element for a search set (e.g. for set A, B, C, we have a query of A). Since we have a list of queries (e.g. for a set A, B, C, we have a query A, B), our query is a subset of the search set, rather than an element. \n",
    "\n",
    "If our query is A, B and the search set is A, B, C, we expect our MRR to be 1. However, using the formula would give us 3/4. So, what we can do is iterate through each element of the query and calculate an MRR, then, *remove* that query element from the subset. \n",
    "\n",
    "It looks something like this:\n",
    "\n",
    "- Query: A, B -> Search Set: A, B, C\n",
    "- Calculate MRR for A -> 1/1\n",
    "- Remove A from the Search Set, which becomes: B, C\n",
    "- Query A -> Search Set: B, C\n",
    "- Calculate MRR for B -> 1/1\n",
    "- Remove B from the Search Set, which becomes: C\n",
    "- Done\n",
    "- Calculate Adjusted MRR with: (MRR_A + MRR_B)/2 = 1\n",
    "\n",
    "BUT, what happens if the query is B, A? We still get an adjusted score of 3/4. To avoid this, we need to *sort* the query to be in the same order as the elements appear in the search set.\n",
    "\n",
    "We use the following formula for finding MRR:\n",
    "\n",
    "$MRR = \\frac{1}{|Q|}\\sum_{i=1}^{|Q|} \\frac{1}{rank_i}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjusted_MRR(bug_report):\n",
    "  fixed_files = bug_report['fix']\n",
    "  project_file_similarities = deepcopy(bug_report['similarities'])\n",
    "\n",
    "  # Sort the fixed files to be in the same order as they appear in the project file similarities\n",
    "  i = 0\n",
    "  temp_fixed_files = []\n",
    "  for similarity in project_file_similarities:\n",
    "    file = similarity[0]\n",
    "    if len(temp_fixed_files) == len(fixed_files):\n",
    "      break\n",
    "    for f in fixed_files:\n",
    "      if f in file or f == file:\n",
    "        temp_fixed_files.append(file)\n",
    "\n",
    "  # Otherwise, we will get an error, if we can't find any documents the score is 0.\n",
    "  if len(temp_fixed_files) == 0:\n",
    "    return 0\n",
    "  fixed_files = temp_fixed_files\n",
    "\n",
    "  # Calculate the MRR for the bug report\n",
    "  adjusted_reciprocals = []\n",
    "  for fixed_file in fixed_files:\n",
    "    # Find the ranking of the fixed file in the similarities array\n",
    "    similarity_index = 1\n",
    "    for i, similarity in enumerate(project_file_similarities):\n",
    "      file, _ = similarity\n",
    "      if file in fixed_file:\n",
    "        similarity_index = i + 1\n",
    "        break\n",
    "\n",
    "    # Calculate the similarity and shift the window\n",
    "    adjusted_reciprocals.append(1 / similarity_index)\n",
    "    del project_file_similarities[similarity_index - 1]\n",
    "\n",
    "  return np.mean(adjusted_reciprocals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP (Mean Average Precision) scores\n",
    "\n",
    "To calculate the MAP, the formula described in the BugLocator paper along with other online research was utilized. There was a bug in the BugLocator paper that showed the variable with an `i` variable that should have been `j`, this was realized using the author's neural net when conducting secondary research. \n",
    "\n",
    "Average Precision of each query (bug):\n",
    "\n",
    "$AvgP_i = \\sum_{j=1}^{M} \\frac{P(j) Ã— pos(j)}{\\text{number of positive instances}}$\n",
    "\n",
    "- Where *M* is the number documents.\n",
    "- *P(j)* is the number of positive instances in the top *j* positions.\n",
    "- *pos(j)* is whether the document at j is equal to a document in the query.\n",
    "- number of positive instances is the total number of query documents that are found in the documents.\n",
    "\n",
    "The MAP is the mean of all precisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_precision(bug_report):\n",
    "  fixed_files = bug_report['fix']\n",
    "  similarities = bug_report['similarities']\n",
    "\n",
    "  # Precompute some queries, otherwise this function will take hours to run if do this in the for loop\n",
    "  fixed_file_indices = []\n",
    "  for fix in fixed_files:\n",
    "    for i in range(len(similarities)):\n",
    "      if fix in similarities[i][0] or fix == similarities[i][0]:\n",
    "        fixed_file_indices.append(i)\n",
    "\n",
    "  # Calculate the average precision outlined in the BugLocator paper\n",
    "  precision = []\n",
    "  for j in range(len(similarities)):\n",
    "    if j + 1 == len(similarities):\n",
    "      break\n",
    "\n",
    "    # Calculate P(j)\n",
    "    number_of_positive_instances_in_top_j = 0\n",
    "    for index in fixed_file_indices:\n",
    "      if index <= j:\n",
    "        number_of_positive_instances_in_top_j += 1\n",
    "    p_j = number_of_positive_instances_in_top_j / (j + 1)\n",
    "\n",
    "    # Calculate pos(j)\n",
    "    pos_j = 0\n",
    "    document_j = similarities[j]\n",
    "    for file in fixed_files:\n",
    "      if file in document_j[0] or file == document_j[0]:\n",
    "        pos_j = 1\n",
    "\n",
    "    precision.append((p_j * pos_j) / len(fixed_files))\n",
    "\n",
    "  return sum(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's calculate the scores\n",
    "\n",
    "Not bad! Actually, not far off of BugLocator for the LANG and SocialFB projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['org.apache.commons.collections.splitmap.abstractiterablegetmapdecorator.java'\n",
      " 'org.apache.commons.collections.splitmap.testtransformedmap.java']\n",
      "[('java.org.apache.commons.collections.map.transformedmap.java', 0.47958037199107556), ('java.org.apache.commons.collections.map.transformedsortedmap.java', 0.4473951848677276), ('java.org.apache.commons.collections.functors.maptransformer.java', 0.44426691251276657), ('test.org.apache.commons.collections.testtransformerutils.java', 0.414375402940074), ('java.org.apache.commons.collections.transformerutils.java', 0.40863593826089084), ('java.org.apache.commons.collections.functors.chainedtransformer.java', 0.3919777521644056), ('java.org.apache.commons.collections.functors.transformerpredicate.java', 0.37384219364379495), ('java.org.apache.commons.collections.functors.switchtransformer.java', 0.3729787314199169), ('java.org.apache.commons.collections.collection.transformedcollection.java', 0.36857191793411687), ('java.org.apache.commons.collections.functors.transformerclosure.java', 0.36491371602163253), ('java.org.apache.commons.collections.map.defaultedmap.java', 0.3494825856651415), ('java.org.apache.commons.collections.functors.noptransformer.java', 0.3466446388313577), ('java.org.apache.commons.collections.functors.stringvaluetransformer.java', 0.3453540532860865), ('test.org.apache.commons.collections.map.testtransformedmap.java', 0.34128335016006417), ('test.org.apache.commons.collections.map.testtransformedsortedmap.java', 0.3390118737974889), ('test.org.apache.commons.collections.collection.testtransformedcollection.java', 0.33871953936866805), ('java.org.apache.commons.collections.set.transformedset.java', 0.33503123005357505), ('java.org.apache.commons.collections.maputils.java', 0.32839126541029084), ('test.org.apache.commons.collections.abstracttestobject.java', 0.32616800147324554), ('java.org.apache.commons.collections.iterators.transformiterator.java', 0.32390054868346635), ('test.org.apache.commons.collections.map.testlazysortedmap.java', 0.32369994354427317), ('java.org.apache.commons.collections.map.unmodifiablemap.java', 0.32156025954068734), ('java.org.apache.commons.collections.functors.exceptiontransformer.java', 0.32155269691666893), ('java.org.apache.commons.collections.map.lazymap.java', 0.30729410702857357), ('java.org.apache.commons.collections.map.unmodifiableorderedmap.java', 0.30612893661796775), ('java.org.apache.commons.collections.map.fixedsizemap.java', 0.30294650227133085), ('java.org.apache.commons.collections.transformer.java', 0.30124809188012525), ('test.org.apache.commons.collections.map.testhashedmap.java', 0.2951632164642605), ('java.org.apache.commons.collections.map.abstractmapdecorator.java', 0.2950168722038964), ('test.org.apache.commons.collections.map.testlazymap.java', 0.29164542639564595), ('java.org.apache.commons.collections.comparators.transformingcomparator.java', 0.2895188888025099), ('java.org.apache.commons.collections.map.unmodifiablesortedmap.java', 0.28924517797008553), ('test.org.apache.commons.collections.map.testflat3map.java', 0.2858408251870993), ('test.org.apache.commons.collections.map.testpredicatedmap.java', 0.28456093887543527), ('test.org.apache.commons.collections.iterators.testunmodifiablemapiterator.java', 0.28407746786232585), ('test.org.apache.commons.collections.mapperformance.java', 0.282760570513551), ('test.org.apache.commons.collections.map.testdefaultedmap.java', 0.28010117940137946), ('java.org.apache.commons.collections.functors.clonetransformer.java', 0.2799155055771682), ('java.org.apache.commons.collections.map.fixedsizesortedmap.java', 0.2792254900944156), ('test.org.apache.commons.collections.map.testpredicatedsortedmap.java', 0.27911835296163867), ('test.org.apache.commons.collections.map.testunmodifiablemap.java', 0.2783234442958806), ('test.org.apache.commons.collections.map.testsingletonmap.java', 0.2734160366149574), ('java.org.apache.commons.collections.functors.transformedpredicate.java', 0.27156877213960584), ('test.org.apache.commons.collections.map.testfixedsizemap.java', 0.26716169826015707), ('test.org.apache.commons.collections.iterators.testunmodifiableorderedmapiterator.java', 0.26692972623605454), ('java.org.apache.commons.collections.iterablemap.java', 0.26673408288162237), ('java.org.apache.commons.collections.bidimap.dualhashbidimap.java', 0.26632124513947875), ('test.org.apache.commons.collections.set.testtransformedset.java', 0.2654615965481884), ('test.org.apache.commons.collections.bidimap.testdualtreebidimap2.java', 0.2642302851123718), ('test.org.apache.commons.collections.map.testunmodifiableorderedmap.java', 0.26399476062772076), ('test.org.apache.commons.collections.functors.testprototypefactory.java', 0.26385704548084143), ('java.org.apache.commons.collections.list.transformedlist.java', 0.2586653268844615), ('test.org.apache.commons.collections.testmaputils.java', 0.25685024292899), ('java.org.apache.commons.collections.fasthashmap.java', 0.2565398797238993), ('test.org.apache.commons.collections.map.abstracttestiterablemap.java', 0.2557740616831619), ('test.org.apache.commons.collections.functors.abstracttestserialization.java', 0.25548042853055464), ('java.org.apache.commons.collections.bidimap.dualtreebidimap.java', 0.2546121276731633), ('java.org.apache.commons.collections.map.lazysortedmap.java', 0.25366402432023566), ('test.org.apache.commons.collections.set.testtransformedsortedset.java', 0.2535099831850906), ('java.org.apache.commons.collections.fasttreemap.java', 0.2527310624196541), ('test.org.apache.commons.collections.map.testunmodifiablesortedmap.java', 0.2517731690022408), ('java.org.apache.commons.collections.map.abstractorderedmapdecorator.java', 0.2514172059231104), ('java.org.apache.commons.collections.map.abstractsortedmapdecorator.java', 0.24959039655070667), ('test.org.apache.commons.collections.map.testfixedsizesortedmap.java', 0.24890365593133038), ('test.org.apache.commons.collections.testmultihashmap.java', 0.24511040834286582), ('test.org.apache.commons.collections.functors.testinvokertransformer.java', 0.24414949366746788), ('java.org.apache.commons.collections.buffer.transformedbuffer.java', 0.24363784830818735), ('java.org.apache.commons.collections.functors.instantiatetransformer.java', 0.24215910636008356), ('test.org.apache.commons.collections.map.abstracttestmap.java', 0.2359504935986012), ('java.org.apache.commons.collections.bidimap.java', 0.23553737008554945), ('java.org.apache.commons.collections.proxymap.java', 0.23546110624592648), ('test.org.apache.commons.collections.functors.testclonetransformer.java', 0.23414107133204123), ('java.org.apache.commons.collections.bag.transformedbag.java', 0.23368207608064062), ('java.org.apache.commons.collections.set.transformedsortedset.java', 0.23050369042705038), ('test.org.apache.commons.collections.testtreemap.java', 0.22970429373280432), ('test.org.apache.commons.collections.map.testmultivaluemap.java', 0.22786247211001298), ('java.org.apache.commons.collections.set.mapbackedset.java', 0.22783606682887955), ('java.org.apache.commons.collections.bidimap.abstractbidimapdecorator.java', 0.22492091242026116), ('test.org.apache.commons.collections.functors.testinstantiatetransformer.java', 0.22362862686894275), ('java.org.apache.commons.collections.map.predicatedsortedmap.java', 0.2229754844641293), ('java.org.apache.commons.collections.functors.invokertransformer.java', 0.22290461063728853), ('test.org.apache.commons.collections.teststaticbucketmap.java', 0.22112922248663971), ('test.org.apache.commons.collections.map.teststaticbucketmap.java', 0.22046435578846113), ('test.org.apache.commons.collections.testreferencemap.java', 0.2195044657317143), ('java.org.apache.commons.collections.map.predicatedmap.java', 0.21772127716880835), ('test.org.apache.commons.collections.map.abstracttestsortedmap.java', 0.21577506387073622), ('java.org.apache.commons.collections.bidimap.unmodifiablebidimap.java', 0.21551437996123385), ('test.org.apache.commons.collections.iterators.abstracttestmapiterator.java', 0.21293756723609114), ('test.org.apache.commons.collections.map.testcaseinsensitivemap.java', 0.21170374277654633), ('java.org.apache.commons.collections.map.hashedmap.java', 0.21095803435371266), ('java.org.apache.commons.collections.bidimap.unmodifiablesortedbidimap.java', 0.20915071726894738), ('java.org.apache.commons.collections.map.typedmap.java', 0.20685252250666714), ('java.org.apache.commons.collections.bidimap.abstractsortedbidimapdecorator.java', 0.20595898492925319), ('test.org.apache.commons.collections.map.testreferencemap.java', 0.20532005930444897), ('java.org.apache.commons.collections.bidimap.abstractdualbidimap.java', 0.2045027283361018), ('test.org.apache.commons.collections.map.testreferenceidentitymap.java', 0.20450011154536288), ('test.org.apache.commons.collections.iterators.abstracttestorderedmapiterator.java', 0.2040026941468574), ('test.org.apache.commons.collections.map.testidentitymap.java', 0.2038792976219708), ('java.org.apache.commons.collections.orderedmap.java', 0.2033485003475782), ('java.org.apache.commons.collections.keyvalue.tiedmapentry.java', 0.2029056448317353), ('test.org.apache.commons.collections.map.testcompositemap.java', 0.20273551934490885), ('java.org.apache.commons.collections.bidimap.unmodifiableorderedbidimap.java', 0.2027308460340012), ('java.org.apache.commons.collections.bag.transformedsortedbag.java', 0.2009417159207607), ('java.org.apache.commons.collections.map.caseinsensitivemap.java', 0.20087585479171247), ('test.org.apache.commons.collections.map.testlrumap.java', 0.20075925386758905), ('java.org.apache.commons.collections.orderedbidimap.java', 0.20071870307530473), ('test.org.apache.commons.collections.bidimap.testtreebidimap.java', 0.2005603902101628), ('test.org.apache.commons.collections.comparators.testreversecomparator.java', 0.19845631693512353), ('java.org.apache.commons.collections.map.singletonmap.java', 0.19734474614737454), ('test.org.apache.commons.collections.testbeanmap.java', 0.19685874243236498), ('java.org.apache.commons.collections.sortedbidimap.java', 0.19490595183755022), ('test.org.apache.commons.collections.testfasttreemap.java', 0.19427254098528288), ('test.org.apache.commons.collections.set.testmapbackedset.java', 0.19420435710460718), ('test.org.apache.commons.collections.buffer.testtransformedbuffer.java', 0.19246348914566075), ('java.org.apache.commons.collections.collection.abstractserializablecollectiondecorator.java', 0.19152922343973755), ('java.org.apache.commons.collections.bidimap.abstractorderedbidimapdecorator.java', 0.1910598494498069), ('test.org.apache.commons.collections.testfasthashmap1.java', 0.19075856322196486), ('test.org.apache.commons.collections.testlrumap.java', 0.19038844635879754), ('test.org.apache.commons.collections.bidimap.testdualhashbidimap.java', 0.18833464294038108), ('test.org.apache.commons.collections.bidimap.abstracttestbidimap.java', 0.1867773334125402), ('java.org.apache.commons.collections.map.typedsortedmap.java', 0.18620374237572473), ('java.org.apache.commons.collections.set.abstractserializablesetdecorator.java', 0.1852259208973441), ('test.org.apache.commons.collections.testfasthashmap.java', 0.18414655899360927), ('java.org.apache.commons.collections.map.listorderedmap.java', 0.1838185317776122), ('java.org.apache.commons.collections.map.multivaluemap.java', 0.18252905724336654), ('test.org.apache.commons.collections.keyvalue.testtiedmapentry.java', 0.18212141249284391), ('java.org.apache.commons.collections.map.abstractinputcheckedmapdecorator.java', 0.180757493591087), ('java.org.apache.commons.collections.list.abstractserializablelistdecorator.java', 0.1797194245483885), ('test.org.apache.commons.collections.map.abstracttestorderedmap.java', 0.1796463171253241), ('test.org.apache.commons.collections.keyvalue.abstracttestmapentry.java', 0.17834050908568247), ('test.org.apache.commons.collections.bidimap.testunmodifiablesortedbidimap.java', 0.17757978003088165), ('test.org.apache.commons.collections.bidimap.testunmodifiablebidimap.java', 0.17669412167350665), ('test.org.apache.commons.collections.list.testtransformedlist.java', 0.17655341039460568), ('test.org.apache.commons.collections.bidimap.testdualtreebidimap.java', 0.17564122392804038), ('java.org.apache.commons.collections.collectionutils.java', 0.1740123548744616), ('java.org.apache.commons.collections.multihashmap.java', 0.17334917477836342), ('java.org.apache.commons.collections.functors.factorytransformer.java', 0.17148853738477715), ('test.org.apache.commons.collections.bidimap.testabstractorderedbidimapdecorator.java', 0.17080884654614625), ('java.org.apache.commons.collections.map.identitymap.java', 0.17053921629152283), ('java.org.apache.commons.collections.keyvalue.abstractmapentrydecorator.java', 0.17015847991238206), ('test.org.apache.commons.collections.map.testlinkedmap.java', 0.16957612619272153), ('java.org.apache.commons.collections.sequencedhashmap.java', 0.16952620942699637), ('test.org.apache.commons.collections.bidimap.testunmodifiableorderedbidimap.java', 0.1694963746932364), ('test.org.apache.commons.collections.testfasttreemap1.java', 0.16837987367646126), ('java.org.apache.commons.collections.map.flat3map.java', 0.16629267638531797), ('java.org.apache.commons.collections.functors.predicatetransformer.java', 0.1647411005532802), ('java.org.apache.commons.collections.iterators.emptymapiterator.java', 0.1637164836108788), ('java.org.apache.commons.collections.beanmap.java', 0.1634082948781656), ('java.org.apache.commons.collections.map.linkedmap.java', 0.16277675979170816), ('test.org.apache.commons.collections.keyvalue.testdefaultmapentry.java', 0.158351822768642), ('test.org.apache.commons.collections.bag.testtransformedsortedbag.java', 0.1570269905114371), ('java.org.apache.commons.collections.functors.functorutils.java', 0.15673465647217125), ('test.org.apache.commons.collections.bag.testtransformedbag.java', 0.1529303335128864), ('test.org.apache.commons.collections.map.testall.java', 0.15280172764068878), ('java.org.apache.commons.collections.defaultmapentry.java', 0.1519849679535261), ('java.org.apache.commons.collections.boundedmap.java', 0.15018982928310637), ('test.org.apache.commons.collections.keyvalue.testunmodifiablemapentry.java', 0.14985121085693748), ('java.org.apache.commons.collections.iterators.entrysetmapiterator.java', 0.1470992829999952), ('java.org.apache.commons.collections.iterators.emptyorderedmapiterator.java', 0.14702673712543446), ('java.org.apache.commons.collections.extendedproperties.java', 0.1458928772377282), ('java.org.apache.commons.collections.bag.abstractmapbag.java', 0.14264078604789152), ('java.org.apache.commons.collections.defaultmapbag.java', 0.1412054579400849), ('java.org.apache.commons.collections.keyvalue.abstractmapentry.java', 0.13949089825233962), ('test.org.apache.commons.collections.map.testlistorderedmap2.java', 0.13877943132176723), ('test.org.apache.commons.collections.set.testmapbackedset2.java', 0.13854602331665347), ('java.org.apache.commons.collections.map.lrumap.java', 0.1366448772605779), ('java.org.apache.commons.collections.functors.constanttransformer.java', 0.13646620115467858), ('test.org.apache.commons.collections.bidimap.abstracttestorderedbidimap.java', 0.13585838544024398), ('java.org.apache.commons.collections.iterators.abstractmapiteratordecorator.java', 0.1358143358497265), ('java.org.apache.commons.collections.map.compositemap.java', 0.13523166942499948), ('test.org.apache.commons.collections.testsequencedhashmap.java', 0.13237072891389012), ('java.org.apache.commons.collections.map.abstracthashedmap.java', 0.1299849989347772), ('java.org.apache.commons.collections.multimap.java', 0.12997053650299023), ('java.org.apache.commons.collections.iterators.unmodifiablemapiterator.java', 0.1294572653407882), ('java.org.apache.commons.collections.bag.treebag.java', 0.12509234690310747), ('test.org.apache.commons.collections.bidimap.testall.java', 0.12429673708091155), ('java.org.apache.commons.collections.iterators.abstractorderedmapiteratordecorator.java', 0.12273412171255252), ('test.org.apache.commons.collections.bulktest.java', 0.12255704127200537), ('java.org.apache.commons.collections.staticbucketmap.java', 0.12074114377952233), ('test.org.apache.commons.collections.collection.abstracttestcollection.java', 0.12048057438314963), ('test.org.apache.commons.collections.functors.testall.java', 0.11805547792955874), ('java.org.apache.commons.collections.map.staticbucketmap.java', 0.11725357389589054), ('java.org.apache.commons.collections.iterators.unmodifiableorderedmapiterator.java', 0.11684246412840174), ('test.org.apache.commons.collections.testextendedproperties.java', 0.11683551322486171), ('test.org.apache.commons.collections.testcollectionutils.java', 0.11596403037314353), ('java.org.apache.commons.collections.map.referencemap.java', 0.11348428675807375), ('java.org.apache.commons.collections.bag.hashbag.java', 0.11253552235782473), ('java.org.apache.commons.collections.map.unmodifiableentryset.java', 0.11241310111301048), ('test.org.apache.commons.collections.iterators.testobjectarrayiterator.java', 0.11158191451611843), ('java.org.apache.commons.collections.functors.closuretransformer.java', 0.11147487471266576), ('java.org.apache.commons.collections.iterators.objectgraphiterator.java', 0.11066091922199334), ('java.org.apache.commons.collections.referencemap.java', 0.11043303387304489), ('java.org.apache.commons.collections.orderedmapiterator.java', 0.10977828804985942), ('java.org.apache.commons.collections.map.abstractlinkedmap.java', 0.10952731518213814), ('test.org.apache.commons.collections.collection.testsynchronizedcollection.java', 0.10857122207746521), ('java.org.apache.commons.collections.map.abstractreferencemap.java', 0.10826047981935422), ('java.org.apache.commons.collections.map.referenceidentitymap.java', 0.10609149301095896), ('test.org.apache.commons.collections.keyvalue.testall.java', 0.10573577752983704), ('test.org.apache.commons.collections.iterators.testobjectarraylistiterator.java', 0.1039617516741514), ('java.org.apache.commons.collections.mapiterator.java', 0.10344928417318845), ('java.org.apache.commons.collections.treebag.java', 0.10207306911188539), ('java.org.apache.commons.collections.lrumap.java', 0.10127879684174847), ('test.org.apache.commons.collections.collection.testunmodifiablecollection.java', 0.10097233703006525), ('java.org.apache.commons.collections.map.multikeymap.java', 0.10082969785596138), ('test.org.apache.commons.collections.collection.testpredicatedcollection.java', 0.10025840217518708), ('java.org.apache.commons.collections.buffer.unmodifiablebuffer.java', 0.09985843710886257), ('test.org.apache.commons.collections.list.testsynchronizedlist.java', 0.09966666057207134), ('test.org.apache.commons.collections.set.testsynchronizedset.java', 0.0988825254736242), ('test.org.apache.commons.collections.iterators.testarraylistiterator.java', 0.09875723418681058), ('test.org.apache.commons.collections.iterators.testobjectarraylistiterator2.java', 0.09867188919836799), ('test.org.apache.commons.collections.collection.testall.java', 0.09816746702896696), ('java.org.apache.commons.collections.functors.prototypefactory.java', 0.0979131353679572), ('java.org.apache.commons.collections.keyvalue.unmodifiablemapentry.java', 0.09521829356940938), ('java.org.apache.commons.collections.keyvalue.defaultmapentry.java', 0.09491629406074673), ('java.org.apache.commons.collections.iteratorutils.java', 0.09477800127356939), ('test.org.apache.commons.collections.bag.testall.java', 0.09409143160400223), ('java.org.apache.commons.collections.functors.nopclosure.java', 0.09408119093365706), ('test.org.apache.commons.collections.set.testunmodifiableset.java', 0.09235389497775535), ('test.org.apache.commons.collections.testall.java', 0.09233421539280134), ('test.org.apache.commons.collections.iterators.testarrayiterator.java', 0.09129056053929299), ('java.org.apache.commons.collections.bag.unmodifiablebag.java', 0.09107677951159912), ('test.org.apache.commons.collections.iterators.testarrayiterator2.java', 0.09059843514264207), ('test.org.apache.commons.collections.functors.testwhileclosure.java', 0.09007463050502504), ('java.org.apache.commons.collections.set.unmodifiablesortedset.java', 0.08921770087570394), ('java.org.apache.commons.collections.bag.unmodifiablesortedbag.java', 0.08866494552551789), ('test.org.apache.commons.collections.set.testall.java', 0.08841568479847377), ('java.org.apache.commons.collections.factory.java', 0.08761078546901711), ('test.org.apache.commons.collections.set.testsynchronizedsortedset.java', 0.08697255653487201), ('test.org.apache.commons.collections.buffer.testsynchronizedbuffer.java', 0.08693749759087117), ('test.org.apache.commons.collections.functors.testforclosure.java', 0.08608905396025461), ('test.org.apache.commons.collections.iterators.testarraylistiterator2.java', 0.08475750796363332), ('test.org.apache.commons.collections.set.testpredicatedsortedset.java', 0.0847196619547759), ('test.org.apache.commons.collections.set.testtypedset.java', 0.08239639345807769), ('test.org.apache.commons.collections.list.testtypedlist.java', 0.08234661476654895), ('java.org.apache.commons.collections.collection.abstractcollectiondecorator.java', 0.0820053593718752), ('java.org.apache.commons.collections.keyvalue.abstractkeyvalue.java', 0.08162298153259677), ('test.org.apache.commons.collections.map.testlistorderedmap.java', 0.08045513776489514), ('java.org.apache.commons.collections.setutils.java', 0.08032040227674857), ('test.org.apache.commons.collections.buffer.testunmodifiablebuffer.java', 0.08015994464415722), ('test.org.apache.commons.collections.list.testfixedsizelist.java', 0.07947718974877718), ('test.org.apache.commons.collections.set.testpredicatedset.java', 0.07905853132101125), ('test.org.apache.commons.collections.testallpackages.java', 0.078332254295994), ('test.org.apache.commons.collections.testtypedcollection.java', 0.07829153204532649), ('java.org.apache.commons.collections.functors.instantiatefactory.java', 0.07817232671711265), ('test.org.apache.commons.collections.testarraylist.java', 0.07815777307672198), ('test.org.apache.commons.collections.testdoubleorderedmap.java', 0.07679570343783805), ('test.org.apache.commons.collections.testhashbag.java', 0.07653488443658073), ('test.org.apache.commons.collections.keyvalue.testmultikey.java', 0.07645161038727616), ('test.org.apache.commons.collections.functors.testinstantiatefactory.java', 0.07645008909266741), ('test.org.apache.commons.collections.list.testall.java', 0.07482778659360292), ('test.org.apache.commons.collections.iterators.testunmodifiableiterator.java', 0.07099364989705015), ('test.org.apache.commons.collections.buffer.testall.java', 0.07083756970545729), ('java.org.apache.commons.collections.keyvalue.defaultkeyvalue.java', 0.07070435678059127), ('test.org.apache.commons.collections.comparators.testall.java', 0.07010403457125876), ('java.org.apache.commons.collections.collection.predicatedcollection.java', 0.06913926652791479), ('test.org.apache.commons.collections.testcursorablelinkedlist.java', 0.06905207882174852), ('test.org.apache.commons.collections.testbagutils.java', 0.06895878056884427), ('test.org.apache.commons.collections.set.testunmodifiablesortedset.java', 0.06816868948185265), ('test.org.apache.commons.collections.list.testunmodifiablelist.java', 0.06806814895189618), ('test.org.apache.commons.collections.list.testpredicatedlist.java', 0.06773235623716836), ('test.org.apache.commons.collections.bidimap.abstracttestsortedbidimap.java', 0.0676569022636101), ('java.org.apache.commons.collections.iterators.arrayiterator.java', 0.06725265479105529), ('test.org.apache.commons.collections.iterators.testall.java', 0.06659396660190206), ('test.org.apache.commons.collections.comparators.testnullcomparator.java', 0.06632287285015644), ('test.org.apache.commons.collections.testboundedfifobuffer.java', 0.0659945875407664), ('test.org.apache.commons.collections.testclosureutils.java', 0.06515479174859004), ('java.org.apache.commons.collections.functors.exceptionpredicate.java', 0.06491188281457096), ('java.org.apache.commons.collections.functors.exceptionfactory.java', 0.06446536890154496), ('test.org.apache.commons.collections.testiteratorutils.java', 0.06270138186773935), ('test.org.apache.commons.collections.buffer.testpredicatedbuffer.java', 0.06266339226497927), ('java.org.apache.commons.collections.hashbag.java', 0.0626140811878277), ('java.org.apache.commons.collections.keyvalue.java', 0.06256808502336936), ('java.org.apache.commons.collections.functors.identitypredicate.java', 0.06248955960444874), ('java.org.apache.commons.collections.functors.equalpredicate.java', 0.06245403327205388), ('java.org.apache.commons.collections.iterators.objectarrayiterator.java', 0.062342814037103296), ('test.org.apache.commons.collections.buffer.testcircularfifobuffer.java', 0.06166401326356741), ('test.org.apache.commons.collections.buffer.testboundedfifobuffer.java', 0.061031184495394505), ('test.org.apache.commons.collections.comparators.abstracttestcomparator.java', 0.0604801929038882), ('java.org.apache.commons.collections.predicateutils.java', 0.060288144373439365), ('java.org.apache.commons.collections.keyvalue.multikey.java', 0.060037108840277), ('java.org.apache.commons.collections.bidimap.treebidimap.java', 0.05990113645041665), ('test.org.apache.commons.collections.testlistutils.java', 0.05939465229277991), ('java.org.apache.commons.collections.functors.notnullpredicate.java', 0.059330065202454374), ('java.org.apache.commons.collections.predicate.java', 0.05857984390307365), ('test.org.apache.commons.collections.list.testcursorablelinkedlist.java', 0.05829760693381994), ('test.org.apache.commons.collections.iterators.testlistiteratorwrapper.java', 0.05740362242761882), ('test.org.apache.commons.collections.iterators.abstracttestiterator.java', 0.05709451414842818), ('java.org.apache.commons.collections.collection.typedcollection.java', 0.056905171399521524), ('java.org.apache.commons.collections.functors.nullpredicate.java', 0.056846851108121425), ('java.org.apache.commons.collections.buffer.java', 0.0563326516797925), ('test.org.apache.commons.collections.set.testtypedsortedset.java', 0.05629772517642907), ('test.org.apache.commons.collections.bag.testhashbag.java', 0.05595771879666803), ('test.org.apache.commons.collections.iterators.testuniquefilteriterator.java', 0.05568635732226427), ('test.org.apache.commons.collections.set.testlistorderedset.java', 0.055308374950112225), ('java.org.apache.commons.collections.functors.exceptionclosure.java', 0.05517852897951638), ('java.org.apache.commons.collections.closureutils.java', 0.05475049724440183), ('java.org.apache.commons.collections.iterators.abstractemptyiterator.java', 0.05474020974121561), ('java.org.apache.commons.collections.iterators.objectarraylistiterator.java', 0.0546125775712865), ('java.org.apache.commons.collections.functors.truepredicate.java', 0.054498368793423235), ('java.org.apache.commons.collections.functors.falsepredicate.java', 0.0540198861755748), ('test.org.apache.commons.collections.iterators.testunmodifiablelistiterator.java', 0.05398847960494444), ('java.org.apache.commons.collections.doubleorderedmap.java', 0.05388972992019629), ('java.org.apache.commons.collections.collection.unmodifiablecollection.java', 0.05322551127563531), ('test.org.apache.commons.collections.bag.testtypedsortedbag.java', 0.05317293832865809), ('test.org.apache.commons.collections.testsetutils.java', 0.05271768693853812), ('test.org.apache.commons.collections.list.testsetuniquelist.java', 0.05250265854395598), ('java.org.apache.commons.collections.set.listorderedset.java', 0.05244116609725325), ('test.org.apache.commons.collections.iterators.testfilteriterator.java', 0.052153936469314766), ('java.org.apache.commons.collections.iterators.arraylistiterator.java', 0.05214860427640769), ('java.org.apache.commons.collections.set.unmodifiableset.java', 0.0520331701469716), ('java.org.apache.commons.collections.unmodifiable.java', 0.05177765045578208), ('java.org.apache.commons.collections.functors.uniquepredicate.java', 0.051423930830335376), ('java.org.apache.commons.collections.functors.predicatedecorator.java', 0.0511394050056049), ('test.org.apache.commons.collections.testfastarraylist1.java', 0.05096758439647643), ('test.org.apache.commons.collections.set.testlistorderedset2.java', 0.050225095474032505), ('java.org.apache.commons.collections.bag.java', 0.049786583370768724), ('test.org.apache.commons.collections.keyvalue.testdefaultkeyvalue.java', 0.04900457846155518), ('test.org.apache.commons.collections.bag.testtypedbag.java', 0.048914387759910215), ('java.org.apache.commons.collections.set.typedset.java', 0.04838629891512119), ('java.org.apache.commons.collections.bagutils.java', 0.04835041031995192), ('java.org.apache.commons.collections.collection.synchronizedcollection.java', 0.04806153806778317), ('test.org.apache.commons.collections.comparators.testcomparablecomparator.java', 0.047893694873933156), ('test.org.apache.commons.collections.buffer.testunboundedfifobuffer.java', 0.0476381054491656), ('java.org.apache.commons.collections.list.predicatedlist.java', 0.04721462906730668), ('test.org.apache.commons.collections.list.abstracttestlist.java', 0.04674968700891649), ('java.org.apache.commons.collections.comparators.fixedordercomparator.java', 0.046588543737437704), ('test.org.apache.commons.collections.bag.abstracttestsortedbag.java', 0.04603216088993495), ('test.org.apache.commons.collections.iterators.testobjectgraphiterator.java', 0.045960418391498406), ('java.org.apache.commons.collections.bag.typedsortedbag.java', 0.04583915071743543), ('test.org.apache.commons.collections.comparators.testfixedordercomparator.java', 0.04570570205859714), ('test.org.apache.commons.collections.testunboundedfifobuffer.java', 0.045653345533076), ('java.org.apache.commons.collections.list.typedlist.java', 0.04564768100369547), ('test.org.apache.commons.collections.bag.testpredicatedbag.java', 0.04515325709218864), ('test.org.apache.commons.collections.testbufferutils.java', 0.045028247163667955), ('java.org.apache.commons.collections.buffer.unboundedfifobuffer.java', 0.04448159042399893), ('java.org.apache.commons.collections.list.unmodifiablelist.java', 0.04430474289517417), ('java.org.apache.commons.collections.set.typedsortedset.java', 0.044019738664990114), ('java.org.apache.commons.collections.functors.switchclosure.java', 0.04365121140210165), ('test.org.apache.commons.collections.bag.testpredicatedsortedbag.java', 0.04348923071978702), ('java.org.apache.commons.collections.iterators.emptyiterator.java', 0.04295586899486121), ('java.org.apache.commons.collections.set.predicatedset.java', 0.04282550835497405), ('java.org.apache.commons.collections.collection.compositecollection.java', 0.04273103318490414), ('test.org.apache.commons.collections.iterators.abstracttestlistiterator.java', 0.04221915086693401), ('java.org.apache.commons.collections.listutils.java', 0.04218713856587524), ('test.org.apache.commons.collections.comparators.testbooleancomparator.java', 0.042103236071357276), ('test.org.apache.commons.collections.set.abstracttestsortedset.java', 0.04156101654777343), ('test.org.apache.commons.collections.iterators.testiteratorchain.java', 0.04110800147301399), ('java.org.apache.commons.collections.functors.forclosure.java', 0.040936515487065256), ('java.org.apache.commons.collections.iterators.singletoniterator.java', 0.04091366742956499), ('java.org.apache.commons.collections.list.lazylist.java', 0.040734136358099235), ('test.org.apache.commons.collections.iterators.testsingletoniterator2.java', 0.04056849315472723), ('java.org.apache.commons.collections.buffer.boundedfifobuffer.java', 0.04036020760239528), ('java.org.apache.commons.collections.iterators.emptylistiterator.java', 0.03969529015016034), ('java.org.apache.commons.collections.set.abstractsetdecorator.java', 0.03953318137032953), ('java.org.apache.commons.collections.collection.unmodifiableboundedcollection.java', 0.039477225989572345), ('test.org.apache.commons.collections.list.testgrowthlist.java', 0.03933386124403678), ('test.org.apache.commons.collections.buffer.testprioritybuffer.java', 0.03906426557685363), ('java.org.apache.commons.collections.comparatorutils.java', 0.03871611949205167), ('java.org.apache.commons.collections.comparators.comparablecomparator.java', 0.03850440998843357), ('test.org.apache.commons.collections.set.abstracttestset.java', 0.03827725969311232), ('java.org.apache.commons.collections.cursorablelinkedlist.java', 0.037810592161904515), ('test.org.apache.commons.collections.collection.testcompositecollection.java', 0.03724457203723428), ('java.org.apache.commons.collections.iterators.filterlistiterator.java', 0.03721365435819437), ('java.org.apache.commons.collections.list.abstractlistdecorator.java', 0.037209340325579), ('test.org.apache.commons.collections.testfactoryutils.java', 0.03666805780684328), ('test.org.apache.commons.collections.map.testmultikeymap.java', 0.03664919813420652), ('test.org.apache.commons.collections.testlinkedlist.java', 0.03662355077353214), ('java.org.apache.commons.collections.iterators.singletonlistiterator.java', 0.036185998345118785), ('java.org.apache.commons.collections.buffer.typedbuffer.java', 0.03611086147126493), ('java.org.apache.commons.collections.fastarraylist.java', 0.03607824704888591), ('java.org.apache.commons.collections.list.fixedsizelist.java', 0.036031189159300786), ('test.org.apache.commons.collections.iterators.testreverselistiterator.java', 0.03582445304067686), ('test.org.apache.commons.collections.buffer.testboundedfifobuffer2.java', 0.03479912371025081), ('test.org.apache.commons.collections.testboundedfifobuffer2.java', 0.03479912371025081), ('java.org.apache.commons.collections.closure.java', 0.03447483100055603), ('java.org.apache.commons.collections.bufferutils.java', 0.034381183661056997), ('java.org.apache.commons.collections.functors.instanceofpredicate.java', 0.03425889533024948), ('java.org.apache.commons.collections.bag.abstractbagdecorator.java', 0.03421035468265791), ('test.org.apache.commons.collections.testtreebag.java', 0.03411751065917419), ('test.org.apache.commons.collections.list.testnodecachinglinkedlist.java', 0.03410658507058886), ('java.org.apache.commons.collections.functors.whileclosure.java', 0.0338764440368093), ('java.org.apache.commons.collections.functors.nullisexceptionpredicate.java', 0.033608480296526425), ('java.org.apache.commons.collections.functorexception.java', 0.033339819717882066), ('java.org.apache.commons.collections.factoryutils.java', 0.03316524192251804), ('java.org.apache.commons.collections.orderediterator.java', 0.03287947530948063), ('test.org.apache.commons.collections.iterators.testsingletoniterator.java', 0.03259058600300724), ('test.org.apache.commons.collections.testarraystack.java', 0.03257038781102338), ('java.org.apache.commons.collections.bag.predicatedbag.java', 0.03242654983191753), ('test.org.apache.commons.collections.localtestnode.java', 0.0323213449870035), ('test.org.apache.commons.collections.testfastarraylist.java', 0.03231475393727781), ('test.org.apache.commons.collections.bag.testtreebag.java', 0.032143576871606114), ('java.org.apache.commons.collections.buffer.abstractbufferdecorator.java', 0.032109080750081107), ('java.org.apache.commons.collections.bag.typedbag.java', 0.031823897520852705), ('java.org.apache.commons.collections.list.setuniquelist.java', 0.031546715801774546), ('java.org.apache.commons.collections.iterators.emptyorderediterator.java', 0.03149461301320791), ('test.org.apache.commons.collections.testenumerationutils.java', 0.031290521621723646), ('java.org.apache.commons.collections.buffer.predicatedbuffer.java', 0.03125698616053336), ('java.org.apache.commons.collections.buffer.prioritybuffer.java', 0.03118722635305779), ('java.org.apache.commons.collections.set.predicatedsortedset.java', 0.031137025960021096), ('java.org.apache.commons.collections.iterators.collatingiterator.java', 0.03064941188393745), ('java.org.apache.commons.collections.iterators.abstractiteratordecorator.java', 0.03043102525347124), ('java.org.apache.commons.collections.set.synchronizedset.java', 0.03028335803853794), ('test.org.apache.commons.collections.buffer.testboundedbuffer.java', 0.03028165529797847), ('test.org.apache.commons.collections.testpredicateutils.java', 0.030183531344114986), ('java.org.apache.commons.collections.set.abstractsortedsetdecorator.java', 0.029907678408904865), ('java.org.apache.commons.collections.iterators.unmodifiablelistiterator.java', 0.029773397530184816), ('java.org.apache.commons.collections.comparators.reversecomparator.java', 0.029415645762514327), ('java.org.apache.commons.collections.functors.anypredicate.java', 0.029339211041738724), ('java.org.apache.commons.collections.list.cursorablelinkedlist.java', 0.02927106944946834), ('test.org.apache.commons.collections.iterators.testloopingiterator.java', 0.029246110693061506), ('java.org.apache.commons.collections.functors.onepredicate.java', 0.029205357864507304), ('java.org.apache.commons.collections.functors.nonepredicate.java', 0.029140958305202663), ('test.org.apache.commons.collections.iterators.testfilterlistiterator.java', 0.028570682164787316), ('java.org.apache.commons.collections.functors.allpredicate.java', 0.028439949450917004), ('java.org.apache.commons.collections.buffer.blockingbuffer.java', 0.028303966574261052), ('java.org.apache.commons.collections.functors.nullistruepredicate.java', 0.028298168753026195), ('java.org.apache.commons.collections.functors.nullisfalsepredicate.java', 0.028297057212071774), ('java.org.apache.commons.collections.iterators.abstractlistiteratordecorator.java', 0.02827801435468078), ('java.org.apache.commons.collections.resettableiterator.java', 0.028203490946239376), ('java.org.apache.commons.collections.arraystack.java', 0.028011981374681853), ('java.org.apache.commons.collections.list.growthlist.java', 0.02749736501705205), ('java.org.apache.commons.collections.iterators.loopingiterator.java', 0.0270305177688675), ('java.org.apache.commons.collections.boundedcollection.java', 0.026853486593248967), ('test.org.apache.commons.collections.comparators.testcomparatorchain.java', 0.02683135827141042), ('java.org.apache.commons.collections.functors.notpredicate.java', 0.026657336810956878), ('java.org.apache.commons.collections.iterators.reverselistiterator.java', 0.026530403746982734), ('java.org.apache.commons.collections.functors.constantfactory.java', 0.02619088962427457), ('java.org.apache.commons.collections.bufferunderflowexception.java', 0.026158714019674335), ('test.org.apache.commons.collections.buffer.testblockingbuffer.java', 0.02613838933905648), ('java.org.apache.commons.collections.binaryheap.java', 0.026110200230013904), ('java.org.apache.commons.collections.list.abstractlinkedlist.java', 0.026027218451086572), ('java.org.apache.commons.collections.resettablelistiterator.java', 0.025960337772366872), ('java.org.apache.commons.collections.list.synchronizedlist.java', 0.02566107006765116), ('java.org.apache.commons.collections.iterators.listiteratorwrapper.java', 0.025525818908786285), ('java.org.apache.commons.collections.bufferoverflowexception.java', 0.02546972274602301), ('java.org.apache.commons.collections.iterators.filteriterator.java', 0.025348601848177197), ('test.org.apache.commons.collections.set.testcompositeset.java', 0.025040955704368494), ('java.org.apache.commons.collections.iterators.unmodifiableiterator.java', 0.02488808682941481), ('java.org.apache.commons.collections.bag.predicatedsortedbag.java', 0.024689827476462586), ('test.org.apache.commons.collections.list.testtreelist.java', 0.024672244323412272), ('test.org.apache.commons.collections.list.testabstractlinkedlist.java', 0.024661717045274655), ('java.org.apache.commons.collections.buffer.circularfifobuffer.java', 0.024069039684919434), ('java.org.apache.commons.collections.bag.abstractsortedbagdecorator.java', 0.02315440415958882), ('java.org.apache.commons.collections.priorityqueue.java', 0.02295755562747901), ('java.org.apache.commons.collections.iterators.iteratorchain.java', 0.022738437547693776), ('java.org.apache.commons.collections.set.synchronizedsortedset.java', 0.022479745800816332), ('java.org.apache.commons.collections.sortedbag.java', 0.02235879714311059), ('java.org.apache.commons.collections.buffer.synchronizedbuffer.java', 0.021406093590523166), ('test.org.apache.commons.collections.testbinaryheap.java', 0.021284682323910085), ('java.org.apache.commons.collections.bag.synchronizedbag.java', 0.0210030070889541), ('test.org.apache.commons.collections.iterators.testsingletonlistiterator.java', 0.020470995225220286), ('java.org.apache.commons.collections.set.compositeset.java', 0.020404515341354203), ('java.org.apache.commons.collections.functors.andpredicate.java', 0.020208308262710317), ('java.org.apache.commons.collections.functors.orpredicate.java', 0.020197561326635673), ('java.org.apache.commons.collections.iterators.uniquefilteriterator.java', 0.0201351871428799), ('java.org.apache.commons.collections.unboundedfifobuffer.java', 0.019892277151285005), ('java.org.apache.commons.collections.comparators.comparatorchain.java', 0.019698594735428263), ('test.org.apache.commons.collections.iterators.testloopinglistiterator.java', 0.019689344398446468), ('java.org.apache.commons.collections.functors.ifclosure.java', 0.01931985870250886), ('java.org.apache.commons.collections.functors.chainedclosure.java', 0.019113514146617196), ('java.org.apache.commons.collections.synchronizedpriorityqueue.java', 0.018812458307779816), ('test.org.apache.commons.collections.iterators.testcollatingiterator.java', 0.018786579436900822), ('java.org.apache.commons.collections.comparators.booleancomparator.java', 0.018734479386021515), ('java.org.apache.commons.collections.boundedfifobuffer.java', 0.018615448411986042), ('test.org.apache.commons.collections.bag.abstracttestbag.java', 0.018427345491692244), ('java.org.apache.commons.collections.iterators.proxylistiterator.java', 0.01684690866413599), ('java.org.apache.commons.collections.comparators.nullcomparator.java', 0.01681267358643964), ('java.org.apache.commons.collections.buffer.boundedbuffer.java', 0.016612158033007484), ('java.org.apache.commons.collections.list.treelist.java', 0.016310446983993605), ('java.org.apache.commons.collections.bag.synchronizedsortedbag.java', 0.01561287008522223), ('java.org.apache.commons.collections.iterators.proxyiterator.java', 0.01538995887948735), ('java.org.apache.commons.collections.iterators.loopinglistiterator.java', 0.014982449859569098), ('java.org.apache.commons.collections.iterators.iteratorenumeration.java', 0.01461825021943829), ('java.org.apache.commons.collections.list.nodecachinglinkedlist.java', 0.012744751960273176), ('java.org.apache.commons.collections.iterators.enumerationiterator.java', 0.012008556603290744), ('java.org.apache.commons.collections.enumerationutils.java', 0.011458669580156509)]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justintijunelis/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def calculate_scores(bug_reports, metric_function, column_name):\n",
    "  # Calculate the average precision for each bug report\n",
    "  for row, bug_report in bug_reports.iterrows():\n",
    "    score = metric_function(bug_report)\n",
    "    bug_reports.at[row, column_name] = score\n",
    "\n",
    "  # Group the project bugs, and compute the net MAP per project\n",
    "  project_bug_reports = [group for _, group in bug_reports.groupby('project')]\n",
    "  project_scores = defaultdict(str)\n",
    "  projects = bug_reports['project'].unique()\n",
    "  for project in projects:\n",
    "    project_scores[project] = 0\n",
    "  for project_bug_report in project_bug_reports:\n",
    "    score = np.mean(project_bug_report[column_name])\n",
    "    project_scores[project_bug_report['project'][0]] = score\n",
    "  \n",
    "  return project_scores\n",
    "\n",
    "# Calculate and plot the MRR\n",
    "project_scores = calculate_scores(bug_reports, calculate_adjusted_MRR, 'adjusted_MRR')\n",
    "project_scores = dict(sorted(project_scores.items(), key=lambda item: item[1]))\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(range(len(project_scores)), list(project_scores.values()), tick_label=list(project_scores.keys()))\n",
    "plt.xlabel('Projects')\n",
    "plt.ylabel('Adjusted MRR Score')\n",
    "plt.title('Adjusted MRR Score for each Project')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot\n",
    "project_scores = calculate_scores(bug_reports, calculate_average_precision, 'average_precision')\n",
    "project_scores = dict(sorted(project_scores.items(), key=lambda item: item[1]))\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.bar(range(len(project_scores)), list(project_scores.values()), tick_label=list(project_scores.keys()))\n",
    "plt.xlabel('Projects')\n",
    "plt.ylabel('MAP Score')\n",
    "plt.title('MAP Score for each Project')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "\n",
    "In this step, we will develop a new IRFL method and comparing to Method 1.\n",
    "\n",
    "We will roughly implement the BugLocator tool. We will use the same preprocessing as TF-IDF code we developed for method 1 to calculate an indirect relevancy function. Then, we will use a weighted average of the direct relevancy function and indirect relevancy function to do the ranking for this method. The indirect function calculates the similarity between the new bug report and the historical ones. Then, given that we already know which exact files have been fixed for each historical bug report. So, we can map files to historical bug reports. Then, the algorithm ranks source files according to their indirect similarity (the similarity of a source file's corresponding historical report(s) to the new bug report) to the new bug report.\n",
    "\n",
    "- Method 2 MUST improve method 1 results.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, let's get our data in order\n",
    "\n",
    "We need to split our bug reports into testing and training sets. Since the bugs are dated, we can sort them to use the newest bugs as our testing set and historical bugs as our training set. We will split the training set as the oldest 80% of the bug reports and the testing set as the newest 20% of the reports.\n",
    "\n",
    "But, we need to be careful! Some projects have more source code than others. We need to make sure we *evenly* split the bug reports into testing and training sets for *each* project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fix</th>\n",
       "      <th>text</th>\n",
       "      <th>fixdate</th>\n",
       "      <th>project</th>\n",
       "      <th>average_precision</th>\n",
       "      <th>similarities</th>\n",
       "      <th>adjusted_MRR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[org.acegisecurity.adapters.jboss.jbossacegilo...</td>\n",
       "      <td>current code use creat princip acegi user toke...</td>\n",
       "      <td>2005-06-26 13:06:38</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(main.java.org.springframework.security.acls....</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[org.acegisecurity.ui.rememberme.remembermepro...</td>\n",
       "      <td>tri start applic latest cv version acegi get f...</td>\n",
       "      <td>2005-07-08 08:21:14</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(test.java.org.springframework.security.authe...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[org.acegisecurity.context.httpsessioncontexti...</td>\n",
       "      <td>http forum springframework org viewtop php htt...</td>\n",
       "      <td>2005-07-11 16:46:19</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(test.java.org.springframework.security.web.c...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[org.acegisecurity.providers.jaas.jaasnamecall...</td>\n",
       "      <td>submit via listserv one develop said would loo...</td>\n",
       "      <td>2005-08-23 02:16:13</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(main.java.org.springframework.security.remot...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[org.acegisecurity.acl.basic.jdbc.jdbcextended...</td>\n",
       "      <td>use jdbc extend dao impl togeth postgr sql fol...</td>\n",
       "      <td>2005-10-20 18:32:44</td>\n",
       "      <td>SEC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(main.java.org.springframework.security.acls....</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>[org.springframework.data.rest.webmvc.json.dom...</td>\n",
       "      <td>follow scenario parent child entiti item eithe...</td>\n",
       "      <td>2016-12-07 17:58:13</td>\n",
       "      <td>DATAREST</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[(main.java.org.springframework.data.rest.core...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>[org.springframework.data.rest.webmvc.json.dom...</td>\n",
       "      <td>follow scenario parent child entiti item eithe...</td>\n",
       "      <td>2016-12-08 09:13:14</td>\n",
       "      <td>DATAREST</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>[(main.java.org.springframework.data.rest.core...</td>\n",
       "      <td>0.043519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>[org.springframework.data.rest.webmvc.json.dom...</td>\n",
       "      <td>demonstr follow project http github com timteb...</td>\n",
       "      <td>2016-12-08 16:50:49</td>\n",
       "      <td>DATAREST</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>[(test.java.org.springframework.data.rest.webm...</td>\n",
       "      <td>0.067982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>[org.springframework.data.mongodb.repository.q...</td>\n",
       "      <td>collect find applic id name fff fff outsid quo...</td>\n",
       "      <td>2016-12-19 17:16:57</td>\n",
       "      <td>DATAMONGO</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>[(test.java.org.springframework.data.mongodb.c...</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>[org.springframework.data.repository.query.ret...</td>\n",
       "      <td>case inherit use project interfac accessor met...</td>\n",
       "      <td>2016-12-21 13:15:19</td>\n",
       "      <td>DATACMNS</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>[(main.java.org.springframework.data.mapping.m...</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fix  \\\n",
       "id                                                        \n",
       "22    [org.acegisecurity.adapters.jboss.jbossacegilo...   \n",
       "27    [org.acegisecurity.ui.rememberme.remembermepro...   \n",
       "20    [org.acegisecurity.context.httpsessioncontexti...   \n",
       "48    [org.acegisecurity.providers.jaas.jaasnamecall...   \n",
       "43    [org.acegisecurity.acl.basic.jdbc.jdbcextended...   \n",
       "...                                                 ...   \n",
       "953   [org.springframework.data.rest.webmvc.json.dom...   \n",
       "956   [org.springframework.data.rest.webmvc.json.dom...   \n",
       "958   [org.springframework.data.rest.webmvc.json.dom...   \n",
       "1565  [org.springframework.data.mongodb.repository.q...   \n",
       "963   [org.springframework.data.repository.query.ret...   \n",
       "\n",
       "                                                   text              fixdate  \\\n",
       "id                                                                             \n",
       "22    current code use creat princip acegi user toke...  2005-06-26 13:06:38   \n",
       "27    tri start applic latest cv version acegi get f...  2005-07-08 08:21:14   \n",
       "20    http forum springframework org viewtop php htt...  2005-07-11 16:46:19   \n",
       "48    submit via listserv one develop said would loo...  2005-08-23 02:16:13   \n",
       "43    use jdbc extend dao impl togeth postgr sql fol...  2005-10-20 18:32:44   \n",
       "...                                                 ...                  ...   \n",
       "953   follow scenario parent child entiti item eithe...  2016-12-07 17:58:13   \n",
       "956   follow scenario parent child entiti item eithe...  2016-12-08 09:13:14   \n",
       "958   demonstr follow project http github com timteb...  2016-12-08 16:50:49   \n",
       "1565  collect find applic id name fff fff outsid quo...  2016-12-19 17:16:57   \n",
       "963   case inherit use project interfac accessor met...  2016-12-21 13:15:19   \n",
       "\n",
       "        project  average_precision  \\\n",
       "id                                   \n",
       "22          SEC           0.000000   \n",
       "27          SEC           0.000000   \n",
       "20          SEC           0.000000   \n",
       "48          SEC           0.000000   \n",
       "43          SEC           0.000000   \n",
       "...         ...                ...   \n",
       "953    DATAREST           0.000000   \n",
       "956    DATAREST           0.060714   \n",
       "958    DATAREST           0.091667   \n",
       "1565  DATAMONGO           0.016667   \n",
       "963    DATACMNS           0.055556   \n",
       "\n",
       "                                           similarities  adjusted_MRR  \n",
       "id                                                                     \n",
       "22    [(main.java.org.springframework.security.acls....      0.000000  \n",
       "27    [(test.java.org.springframework.security.authe...      0.000000  \n",
       "20    [(test.java.org.springframework.security.web.c...      0.000000  \n",
       "48    [(main.java.org.springframework.security.remot...      0.000000  \n",
       "43    [(main.java.org.springframework.security.acls....      0.000000  \n",
       "...                                                 ...           ...  \n",
       "953   [(main.java.org.springframework.data.rest.core...      0.000000  \n",
       "956   [(main.java.org.springframework.data.rest.core...      0.043519  \n",
       "958   [(test.java.org.springframework.data.rest.webm...      0.067982  \n",
       "1565  [(test.java.org.springframework.data.mongodb.c...      0.033333  \n",
       "963   [(main.java.org.springframework.data.mapping.m...      0.166667  \n",
       "\n",
       "[1858 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bugs = bug_reports.copy()\n",
    "bugs.sort_values('fixdate', inplace = True)\n",
    "display(bugs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3\n",
    "\n",
    "This is our brand new FL technique applicable on this dataset. The novel approach should use a machine learning/information retrieval method that is not taught in class. It is okay if the method is already proposed in the FL literature and is published, however, your code cannot be copy-pasted. This method does not need to outperform the other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59492509ee09bb1e98cb3b73aca52e57ed875f73ef434eaac26b9b50866a2d0e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
